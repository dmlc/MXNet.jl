<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="no-js ie6"><![endif]-->
<!--[if IE 7 ]><html class="no-js ie7"><![endif]-->
<!--[if IE 8 ]><html class="no-js ie8"><![endif]-->
<!--[if IE 9 ]><html class="no-js ie9"><![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html class="no-js"> <!--<![endif]-->
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1">
    
      
        <title>NDArray API - MXNet.jl</title>
      
      
      
      
    
    <meta property="og:url" content="None">
    <meta property="og:title" content="MXNet.jl">
    <meta property="og:image" content="None/../../">
    <meta name="apple-mobile-web-app-title" content="MXNet.jl">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    
    
    <link rel="shortcut icon" type="image/x-icon" href="../../assets/images/favicon-e565ddfa3b.ico">
    <link rel="icon" type="image/x-icon" href="../../assets/images/favicon-e565ddfa3b.ico">
    <style>
      @font-face {
      	font-family: 'Icon';
      	src: url('../../assets/fonts/icon.eot?52m981');
      	src: url('../../assets/fonts/icon.eot?#iefix52m981')
               format('embedded-opentype'),
      		   url('../../assets/fonts/icon.woff?52m981')
               format('woff'),
      		   url('../../assets/fonts/icon.ttf?52m981')
               format('truetype'),
      		   url('../../assets/fonts/icon.svg?52m981#icon')
               format('svg');
      	font-weight: normal;
      	font-style: normal;
      }
    </style>
    <link rel="stylesheet" href="../../assets/stylesheets/application-a422ff04cc.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/palettes-05ab2406df.css">
    
    
      
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,700|Ubuntu+Mono">
      <style>
        body, input {
          font-family: 'Ubuntu', Helvetica, Arial, sans-serif;
        }
        pre, code {
          font-family: 'Ubuntu Mono', 'Courier New', 'Courier', monospace;
        }
      </style>
    
    
      <link rel="stylesheet" href="../../assets/Documenter.css">
    
    <script src="../../assets/javascripts/modernizr-4ab42b99fd.js"></script>
    
  </head>
  
  
  
  <body class="palette-primary-indigo palette-accent-blue">
    
      
      
    
    <div class="backdrop">
      <div class="backdrop-paper"></div>
    </div>
    <input class="toggle" type="checkbox" id="toggle-drawer">
    <input class="toggle" type="checkbox" id="toggle-search">
    <label class="toggle-button overlay" for="toggle-drawer"></label>
    <header class="header">
      <nav aria-label="Header">
  <div class="bar default">
    <div class="button button-menu" role="button" aria-label="Menu">
      <label class="toggle-button icon icon-menu" for="toggle-drawer">
        <span></span>
      </label>
    </div>
    <div class="stretch">
      <div class="title">
        
          <span class="path">
            
              
                API Documentation <i class="icon icon-link"></i>
              
            
          </span>
        
        NDArray API
      </div>
    </div>
    
    
    <div class="button button-search" role="button" aria-label="Search">
      <label class="toggle-button icon icon-search" title="Search" for="toggle-search"></label>
    </div>
  </div>
  <div class="bar search">
    <div class="button button-close" role="button" aria-label="Close">
      <label class="toggle-button icon icon-back" for="toggle-search"></label>
    </div>
    <div class="stretch">
      <div class="field">
        <input class="query" type="text" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck>
      </div>
    </div>
    <div class="button button-reset" role="button" aria-label="Search">
      <button class="toggle-button icon icon-close" id="reset-search"></button>
    </div>
  </div>
</nav>
    </header>
    <main class="main">
      
      <div class="drawer">
        <nav aria-label="Navigation">
  
  <a href="https://github.com/dmlc/MXNet.jl" class="project">
    <div class="banner">
      
      <div class="name">
        <strong>
          MXNet.jl
          <span class="version">
            
          </span>
        </strong>
        
          <br>
          dmlc/MXNet.jl
        
      </div>
    </div>
  </a>
  <div class="scrollable">
    <div class="wrapper">
      
        <ul class="repo">
          <li class="repo-download">
            
            <a href="https://github.com/dmlc/MXNet.jl/archive/master.zip" target="_blank" title="Download" data-action="download">
              <i class="icon icon-download"></i> Download
            </a>
          </li>
          <li class="repo-stars">
            <a href="https://github.com/dmlc/MXNet.jl/stargazers" target="_blank" title="Stargazers" data-action="star">
              <i class="icon icon-star"></i> Stars
              <span class="count">&ndash;</span>
            </a>
          </li>
        </ul>
        <hr>
      
      <div class="toc">
        <ul>
          
            
  <li>
    <a class="" title="Home" href="../..">
      Home
    </a>
    
  </li>

          
            
  <li>
    <span class="section">Tutorial</span>
    <ul>
      
        
  <li>
    <a class="" title="Digit Recognition on MNIST" href="../../tutorial/mnist/">
      Digit Recognition on MNIST
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Generating Random Sentence with LSTM RNN" href="../../tutorial/char-lstm/">
      Generating Random Sentence with LSTM RNN
    </a>
    
  </li>

      
    </ul>
  </li>

          
            
  <li>
    <span class="section">User Guide</span>
    <ul>
      
        
  <li>
    <a class="" title="Installation Guide" href="../../user-guide/install/">
      Installation Guide
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Overview" href="../../user-guide/overview/">
      Overview
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="FAQ" href="../../user-guide/faq/">
      FAQ
    </a>
    
  </li>

      
    </ul>
  </li>

          
            
  <li>
    <span class="section">API Documentation</span>
    <ul>
      
        
  <li>
    <a class="" title="Context" href="../context/">
      Context
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Models" href="../model/">
      Models
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Initializers" href="../initializer/">
      Initializers
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Optimizers" href="../optimizer/">
      Optimizers
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Callbacks in training" href="../callback/">
      Callbacks in training
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Evaluation Metrics" href="../metric/">
      Evaluation Metrics
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Data Providers" href="../io/">
      Data Providers
    </a>
    
  </li>

      
        
  <li>
    <a class="current" title="NDArray API" href="./">
      NDArray API
    </a>
    
      
        
      
      
    
  </li>

      
        
  <li>
    <a class="" title="Symbolic API" href="../symbolic-node/">
      Symbolic API
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Neural Networks Factory" href="../nn-factory/">
      Neural Networks Factory
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Executor" href="../executor/">
      Executor
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Network Visualization" href="../visualize/">
      Network Visualization
    </a>
    
  </li>

      
    </ul>
  </li>

          
        </ul>
        
      </div>
    </div>
  </div>
</nav>
      </div>
      <article class="article">
        <div class="wrapper">
          
          <p><a id='NDArray-API-1'></a></p>
<h1 id="ndarray-api">NDArray API</h1>
<p><a id='MXNet.mx.NDArray' href='#MXNet.mx.NDArray'>#</a>
<strong><code>MXNet.mx.NDArray</code></strong> &mdash; <em>Type</em>.</p>
<pre><code>NDArray
</code></pre>

<p>Wrapper of the <code>NDArray</code> type in <code>libmxnet</code>. This is the basic building block of tensor-based computation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>since C/C++ use row-major ordering for arrays while Julia follows a   column-major ordering. To keep things consistent, we keep the underlying data   in their original layout, but use <em>language-native</em> convention when we talk   about shapes. For example, a mini-batch of 100 MNIST images is a tensor of   C/C++/Python shape (100,1,28,28), while in Julia, the same piece of memory   have shape (28,28,1,100).</p>
</div>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L70-L83' class='documenter-source'>source</a><br></p>
<p><a id='Base.:*-Tuple{MXNet.mx.NDArray,Real}' href='#Base.:*-Tuple{MXNet.mx.NDArray,Real}'>#</a>
<strong><code>Base.:*</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>*(arg0, arg1)
</code></pre>

<p>Currently only multiplication a scalar with an <code>NDArray</code> is implemented. Matrix multiplication is to be added soon.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L623-L628' class='documenter-source'>source</a><br></p>
<p><a id='Base.:+-Tuple{MXNet.mx.NDArray,Vararg{Union{MXNet.mx.NDArray,Real},N}}' href='#Base.:+-Tuple{MXNet.mx.NDArray,Vararg{Union{MXNet.mx.NDArray,Real},N}}'>#</a>
<strong><code>Base.:+</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>+(args...)
.+(args...)
</code></pre>

<p>Summation. Multiple arguments of either scalar or <code>NDArray</code> could be added together. Note at least the first or second argument needs to be an <code>NDArray</code> to avoid ambiguity of built-in summation.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L526-L533' class='documenter-source'>source</a><br></p>
<p><a id='Base.:--Tuple{MXNet.mx.NDArray,Union{MXNet.mx.NDArray,Real}}' href='#Base.:--Tuple{MXNet.mx.NDArray,Union{MXNet.mx.NDArray,Real}}'>#</a>
<strong><code>Base.:-</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>-(arg0, arg1)
-(arg0)
.-(arg0, arg1)
</code></pre>

<p>Subtraction <code>arg0 - arg1</code>, of scalar types or <code>NDArray</code>. Or create the negative of <code>arg0</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L564-L571' class='documenter-source'>source</a><br></p>
<p><a id='Base.:.*-Tuple{MXNet.mx.NDArray,Union{MXNet.mx.NDArray,Real}}' href='#Base.:.*-Tuple{MXNet.mx.NDArray,Union{MXNet.mx.NDArray,Real}}'>#</a>
<strong><code>Base.:.*</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>.*(arg0, arg1)
</code></pre>

<p>Elementwise multiplication of <code>arg0</code> and <code>arg</code>, could be either scalar or <code>NDArray</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L610-L614' class='documenter-source'>source</a><br></p>
<p><a id='Base.:./-Tuple{MXNet.mx.NDArray,Union{MXNet.mx.NDArray,Real}}' href='#Base.:./-Tuple{MXNet.mx.NDArray,Union{MXNet.mx.NDArray,Real}}'>#</a>
<strong><code>Base.:./</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>./(arg0 :: NDArray, arg :: Union{Real, NDArray})
</code></pre>

<p>Elementwise dividing an <code>NDArray</code> by a scalar or another <code>NDArray</code> of the same shape.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L652-L656' class='documenter-source'>source</a><br></p>
<p><a id='Base.:/-Tuple{MXNet.mx.NDArray,Real}' href='#Base.:/-Tuple{MXNet.mx.NDArray,Real}'>#</a>
<strong><code>Base.:/</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>/(arg0 :: NDArray, arg :: Real)
</code></pre>

<p>Divide an <code>NDArray</code> by a scalar. Matrix division (solving linear systems) is not implemented yet.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L662-L666' class='documenter-source'>source</a><br></p>
<p><a id='Base.LinAlg.dot-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.LinAlg.dot-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.LinAlg.dot</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>dot(lhs, rhs)
</code></pre>

<p>Calculate dot product of two matrices or two vectors</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='Base.LinAlg.norm-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.LinAlg.norm-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.LinAlg.norm</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>norm(src)
</code></pre>

<p>Take L2 norm of the src.The result will be ndarray of shape (1,) on the same device.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='Base._div-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base._div-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base._div</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_div(lhs, rhs)
</code></pre>

<p>Multiply lhs by rhs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='Base.abs-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.abs-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.abs</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>abs(src)
</code></pre>

<p>Take absolute value of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='Base.ceil-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.ceil-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.ceil</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>ceil(src)
</code></pre>

<p>Take ceil value of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='Base.convert-Tuple{Type{Array{T<:Real,N}},MXNet.mx.NDArray}' href='#Base.convert-Tuple{Type{Array{T<:Real,N}},MXNet.mx.NDArray}'>#</a>
<strong><code>Base.convert</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>convert(::Type{Array{T}}, arr :: NDArray)
</code></pre>

<p>Convert an <code>NDArray</code> into a Julia <code>Array</code> of specific type. Data will be copied.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L461-L465' class='documenter-source'>source</a><br></p>
<p><a id='Base.copy!-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.copy!-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.copy!</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>copy!(dst :: Union{NDArray, Array}, src :: Union{NDArray, Array})
</code></pre>

<p>Copy contents of <code>src</code> into <code>dst</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L389-L393' class='documenter-source'>source</a><br></p>
<p><a id='Base.copy-Tuple{MXNet.mx.NDArray}' href='#Base.copy-Tuple{MXNet.mx.NDArray}'>#</a>
<strong><code>Base.copy</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>copy(arr :: NDArray)
copy(arr :: NDArray, ctx :: Context)
copy(arr :: Array, ctx :: Context)
</code></pre>

<p>Create a copy of an array. When no <code>Context</code> is given, create a Julia <code>Array</code>. Otherwise, create an <code>NDArray</code> on the specified context.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L435-L442' class='documenter-source'>source</a><br></p>
<p><a id='Base.cos-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.cos-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.cos</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>cos(src)
</code></pre>

<p>Take cos of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='Base.eltype-Tuple{T<:Union{MXNet.mx.MX_NDArrayHandle,MXNet.mx.NDArray}}' href='#Base.eltype-Tuple{T<:Union{MXNet.mx.MX_NDArrayHandle,MXNet.mx.NDArray}}'>#</a>
<strong><code>Base.eltype</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>eltype(arr :: NDArray)
</code></pre>

<p>Get the element type of an <code>NDArray</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L272-L276' class='documenter-source'>source</a><br></p>
<p><a id='Base.exp-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.exp-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.exp</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>exp(src)
</code></pre>

<p>Take exp of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='Base.floor-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.floor-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.floor</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>floor(src)
</code></pre>

<p>Take floor value of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='Base.getindex-Tuple{MXNet.mx.NDArray,Colon}' href='#Base.getindex-Tuple{MXNet.mx.NDArray,Colon}'>#</a>
<strong><code>Base.getindex</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>getindex(arr :: NDArray, idx)
</code></pre>

<p>Shortcut for <a href="./#Base.slice-Tuple{MXNet.mx.NDArray,Colon}"><code>slice</code></a>. A typical use is to write</p>
<pre><code class="julia">  arr[:] += 5
</code></pre>

<p>which translates into</p>
<pre><code class="julia">  arr[:] = arr[:] + 5
</code></pre>

<p>which furthur translates into</p>
<pre><code class="julia">  setindex!(getindex(arr, Colon()), 5, Colon())
</code></pre>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The behavior is quite different from indexing into Julia's <code>Array</code>. For example, <code>arr[2:5]</code> create a <strong>copy</strong> of the sub-array for Julia <code>Array</code>, while for <code>NDArray</code>, this is a <em>slice</em> that shares the memory.</p>
</div>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L350-L375' class='documenter-source'>source</a><br></p>
<p><a id='Base.getindex-Tuple{MXNet.mx.NDArray,UnitRange{Int64}}' href='#Base.getindex-Tuple{MXNet.mx.NDArray,UnitRange{Int64}}'>#</a>
<strong><code>Base.getindex</code></strong> &mdash; <em>Method</em>.</p>
<p>Shortcut for <a href="./#Base.slice-Tuple{MXNet.mx.NDArray,Colon}"><code>slice</code></a>. <strong>NOTE</strong> the behavior for Julia's built-in index slicing is to create a copy of the sub-array, while here we simply call <code>slice</code>, which shares the underlying memory.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L380-L383' class='documenter-source'>source</a><br></p>
<p><a id='Base.length-Tuple{MXNet.mx.NDArray}' href='#Base.length-Tuple{MXNet.mx.NDArray}'>#</a>
<strong><code>Base.length</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>length(arr :: NDArray)
</code></pre>

<p>Get the number of elements in an <code>NDArray</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L254-L258' class='documenter-source'>source</a><br></p>
<p><a id='Base.log-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.log-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.log</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>log(src)
</code></pre>

<p>Take log of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='Base.max-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.max-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.max</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>max(src, axis, keepdims)
</code></pre>

<p>Take max of the src in the given axis and returns a NDArray. Follows numpy semantics.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>axis::Shape(tuple), optional, default=()</code>: Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.</li>
<li><code>keepdims::boolean, optional, default=False</code>: Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1119' class='documenter-source'>source</a><br></p>
<p><a id='Base.min-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.min-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.min</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>min(src, axis, keepdims)
</code></pre>

<p>Take min of the src in the given axis and returns a NDArray. Follows numpy semantics.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>axis::Shape(tuple), optional, default=()</code>: Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.</li>
<li><code>keepdims::boolean, optional, default=False</code>: Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1119' class='documenter-source'>source</a><br></p>
<p><a id='Base.ndims-Tuple{MXNet.mx.NDArray}' href='#Base.ndims-Tuple{MXNet.mx.NDArray}'>#</a>
<strong><code>Base.ndims</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>ndims(arr :: NDArray)
</code></pre>

<p>Get the number of dimensions of an <code>NDArray</code>. Is equivalent to <code>length(size(arr))</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L263-L267' class='documenter-source'>source</a><br></p>
<p><a id='Base.round-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.round-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.round</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>round(src)
</code></pre>

<p>Take round value of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='Base.setindex!-Tuple{MXNet.mx.NDArray,Real,Colon}' href='#Base.setindex!-Tuple{MXNet.mx.NDArray,Real,Colon}'>#</a>
<strong><code>Base.setindex!</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>setindex!(arr :: NDArray, val, idx)
</code></pre>

<p>Assign values to an <code>NDArray</code>. Elementwise assignment is not implemented, only the following scenarios are supported</p>
<ul>
<li><code>arr[:] = val</code>: whole array assignment, <code>val</code> could be a scalar or an array (Julia <code>Array</code> or <code>NDArray</code>) of the same shape.</li>
<li><code>arr[start:stop] = val</code>: assignment to a <em>slice</em>, <code>val</code> could be a scalar or an array of the same shape to the slice. See also <a href="./#Base.slice-Tuple{MXNet.mx.NDArray,Colon}"><code>slice</code></a>.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L323-L333' class='documenter-source'>source</a><br></p>
<p><a id='Base.sign-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.sign-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.sign</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>sign(src)
</code></pre>

<p>Take sign value of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='Base.sin-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.sin-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.sin</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>sin(src)
</code></pre>

<p>Take sin of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='Base.size-Tuple{MXNet.mx.NDArray}' href='#Base.size-Tuple{MXNet.mx.NDArray}'>#</a>
<strong><code>Base.size</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>size(arr :: NDArray)
size(arr :: NDArray, dim :: Int)
</code></pre>

<p>Get the shape of an <code>NDArray</code>. The shape is in Julia's column-major convention. See also the notes on NDArray shapes <a href="./#MXNet.mx.NDArray"><code>NDArray</code></a>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L236-L242' class='documenter-source'>source</a><br></p>
<p><a id='Base.slice-Tuple{MXNet.mx.NDArray,Colon}' href='#Base.slice-Tuple{MXNet.mx.NDArray,Colon}'>#</a>
<strong><code>Base.slice</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>slice(arr :: NDArray, start:stop)
</code></pre>

<p>Create a view into a sub-slice of an <code>NDArray</code>. Note only slicing at the slowest changing dimension is supported. In Julia's column-major perspective, this is the last dimension. For example, given an <code>NDArray</code> of shape (2,3,4), <code>slice(array, 2:3)</code> will create a <code>NDArray</code> of shape (2,3,2), sharing the data with the original array. This operation is used in data parallelization to split mini-batch into sub-batches for different devices.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L293-L301' class='documenter-source'>source</a><br></p>
<p><a id='Base.sqrt-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.sqrt-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.sqrt</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>sqrt(src)
</code></pre>

<p>Take sqrt of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='Base.sum-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.sum-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.sum</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>sum(src, axis, keepdims)
</code></pre>

<p>Take sum of the src in the given axis and returns a NDArray. Follows numpy semantics.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>axis::Shape(tuple), optional, default=()</code>: Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.</li>
<li><code>keepdims::boolean, optional, default=False</code>: Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1119' class='documenter-source'>source</a><br></p>
<p><a id='Base.transpose-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#Base.transpose-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>Base.transpose</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>transpose(src, axes)
</code></pre>

<p>Transpose the input matrix and return a new one</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>axes::Shape(tuple), optional, default=()</code>: Target axis order. By default the axes will be inverted.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._broadcast-Tuple{MXNet.mx.NDArray,Real,Real,MXNet.mx.NDArray}' href='#MXNet.mx._broadcast-Tuple{MXNet.mx.NDArray,Real,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._broadcast</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_broadcast(src, axis, size)
</code></pre>

<p>Broadcast array in the given axis to the given size</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: source ndarray</li>
<li><code>axis::int</code>: axis to broadcast</li>
<li><code>size::int</code>: size of broadcast</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1119' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._copyto-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx._copyto-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._copyto</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_copyto(src)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._crop_assign-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx._crop_assign-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._crop_assign</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_crop_assign(lhs, rhs, begin, end)
</code></pre>

<p>Assign the rhs to a cropped subset of lhs.</p>
<p><strong>Requirements</strong></p>
<ul>
<li>output should be explicitly given and be the same as lhs.</li>
<li>lhs and rhs are of the same data type, and on the same device.</li>
</ul>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
<li><code>begin::Shape(tuple), required</code>: starting coordinates</li>
<li><code>end::Shape(tuple), required</code>: ending coordinates</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1127' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._crop_assign_scalar-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx._crop_assign_scalar-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._crop_assign_scalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_crop_assign_scalar(src, begin, end, scalar)
</code></pre>

<p>Assign the scalar to a cropped subset of the input.</p>
<p><strong>Requirements</strong></p>
<ul>
<li>output should be explicitly given and be the same as input</li>
</ul>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>begin::Shape(tuple), required</code>: starting coordinates</li>
<li><code>end::Shape(tuple), required</code>: ending coordinates</li>
<li><code>scalar::float, optional, default=0</code>: The scalar value for assignment.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1126' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._div_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}' href='#MXNet.mx._div_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._div_scalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_div_scalar(src, scalar)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>scalar::float</code>: scalar input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._get_ndarray_functions-Tuple{}' href='#MXNet.mx._get_ndarray_functions-Tuple{}'>#</a>
<strong><code>MXNet.mx._get_ndarray_functions</code></strong> &mdash; <em>Method</em>.</p>
<p>The libxmnet APIs are automatically imported from <code>libmxnet.so</code>. The functions listed here operate on <code>NDArray</code> objects. The arguments to the functions are typically ordered as</p>
<pre><code class="julia">  func_name(arg_in1, arg_in2, ..., scalar1, scalar2, ..., arg_out1, arg_out2, ...)
</code></pre>

<p>unless <code>NDARRAY_ARG_BEFORE_SCALAR</code> is not set. In this case, the scalars are put before the input arguments:</p>
<pre><code class="julia">  func_name(scalar1, scalar2, ..., arg_in1, arg_in2, ..., arg_out1, arg_out2, ...)
</code></pre>

<p>If <code>ACCEPT_EMPTY_MUTATE_TARGET</code> is set. An overloaded function without the output arguments will also be defined:</p>
<pre><code class="julia">  func_name(arg_in1, arg_in2, ..., scalar1, scalar2, ...)
</code></pre>

<p>Upon calling, the output arguments will be automatically initialized with empty NDArrays.</p>
<p>Those functions always return the output arguments. If there is only one output (the typical situation), that object (<code>NDArray</code>) is returned. Otherwise, a tuple containing all the outputs will be returned.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L924-L949' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._imdecode-Tuple{MXNet.mx.NDArray,Real,Real,Real,Real,Real,Real,Real,MXNet.mx.NDArray}' href='#MXNet.mx._imdecode-Tuple{MXNet.mx.NDArray,Real,Real,Real,Real,Real,Real,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._imdecode</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_imdecode(mean, index, x0, y0, x1, y1, c, size)
</code></pre>

<p>Decode an image, clip to (x0, y0, x1, y1), subtract mean, and write to buffer</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>mean::NDArray</code>: image mean</li>
<li><code>index::int</code>: buffer position for output</li>
<li><code>x0::int</code>: x0</li>
<li><code>y0::int</code>: y0</li>
<li><code>x1::int</code>: x1</li>
<li><code>y1::int</code>: y1</li>
<li><code>c::int</code>: channel</li>
<li><code>size::int</code>: length of str_img</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1129' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._maximum-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx._maximum-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._maximum</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_maximum(lhs, rhs)
</code></pre>

<p>Elementwise max of lhs by rhs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._maximum_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}' href='#MXNet.mx._maximum_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._maximum_scalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_maximum_scalar(src, scalar)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>scalar::float</code>: scalar input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._minimum-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx._minimum-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._minimum</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_minimum(lhs, rhs)
</code></pre>

<p>Elementwise min of lhs by rhs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._minimum_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}' href='#MXNet.mx._minimum_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._minimum_scalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_minimum_scalar(src, scalar)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>scalar::float</code>: scalar input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._minus-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx._minus-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._minus</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_minus(lhs, rhs)
</code></pre>

<p>Minus lhs and rhs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._minus_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}' href='#MXNet.mx._minus_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._minus_scalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_minus_scalar(src, scalar)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>scalar::float</code>: scalar input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._mul-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx._mul-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._mul</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_mul(lhs, rhs)
</code></pre>

<p>Multiply lhs and rhs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._mul_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}' href='#MXNet.mx._mul_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._mul_scalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_mul_scalar(src, scalar)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>scalar::float</code>: scalar input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._onehot_encode-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx._onehot_encode-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._onehot_encode</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_onehot_encode(lhs, rhs)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand to the function.</li>
<li><code>rhs::NDArray</code>: Right operand to the function.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._plus-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx._plus-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._plus</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_plus(lhs, rhs)
</code></pre>

<p>Add lhs and rhs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._plus_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}' href='#MXNet.mx._plus_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._plus_scalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_plus_scalar(src, scalar)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>scalar::float</code>: scalar input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._power-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx._power-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._power</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_power(lhs, rhs)
</code></pre>

<p>Elementwise power(lhs, rhs)</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._power_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}' href='#MXNet.mx._power_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._power_scalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_power_scalar(src, scalar)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>scalar::float</code>: scalar input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._random_gaussian-Tuple{Real,Real,MXNet.mx.NDArray}' href='#MXNet.mx._random_gaussian-Tuple{Real,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._random_gaussian</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_random_gaussian()
</code></pre>

<p><strong>Arguments</strong></p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1114' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._random_uniform-Tuple{Real,Real,MXNet.mx.NDArray}' href='#MXNet.mx._random_uniform-Tuple{Real,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._random_uniform</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_random_uniform()
</code></pre>

<p><strong>Arguments</strong></p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1114' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._rdiv_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}' href='#MXNet.mx._rdiv_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._rdiv_scalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_rdiv_scalar(src, scalar)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>scalar::float</code>: scalar input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._rminus_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}' href='#MXNet.mx._rminus_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._rminus_scalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_rminus_scalar(src, scalar)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>scalar::float</code>: scalar input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._rpower_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}' href='#MXNet.mx._rpower_scalar-Tuple{MXNet.mx.NDArray,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._rpower_scalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_rpower_scalar(src, scalar)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>scalar::float</code>: scalar input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._sample_normal-Tuple{MXNet.mx.NDArray}' href='#MXNet.mx._sample_normal-Tuple{MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._sample_normal</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_sample_normal(loc, scale, shape)
</code></pre>

<p>Sample a normal distribution</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>loc::float, optional, default=0</code>: Mean of the distribution.</li>
<li><code>scale::float, optional, default=1</code>: Standard deviation of the distribution.</li>
<li><code>shape::Shape(tuple), required</code>: The shape of the output</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1119' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._sample_uniform-Tuple{MXNet.mx.NDArray}' href='#MXNet.mx._sample_uniform-Tuple{MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._sample_uniform</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_sample_uniform(low, high, shape)
</code></pre>

<p>Sample a uniform distribution</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>low::float, optional, default=0</code>: The lower bound of distribution</li>
<li><code>high::float, optional, default=1</code>: The upper bound of distribution</li>
<li><code>shape::Shape(tuple), required</code>: The shape of the output</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1119' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._set_value-Tuple{Real,MXNet.mx.NDArray}' href='#MXNet.mx._set_value-Tuple{Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx._set_value</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_set_value(src)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::real_t</code>: Source input to the function.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.add_to!-Tuple{MXNet.mx.NDArray,Vararg{Union{MXNet.mx.NDArray,Real},N}}' href='#MXNet.mx.add_to!-Tuple{MXNet.mx.NDArray,Vararg{Union{MXNet.mx.NDArray,Real},N}}'>#</a>
<strong><code>MXNet.mx.add_to!</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>add_to!(dst :: NDArray, args :: Union{Real, NDArray}...)
</code></pre>

<p>Add a bunch of arguments into <code>dst</code>. Inplace updating.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L507-L511' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.argmax_channel-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.argmax_channel-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.argmax_channel</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>argmax_channel(src)
</code></pre>

<p>Take argmax indices of each channel of the src.The result will be ndarray of shape (num_channel,) on the same device.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.batch_dot-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.batch_dot-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.batch_dot</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>batch_dot(lhs, rhs)
</code></pre>

<p>Calculate batched dot product of two matrices. (batch, M, K) batch_dot (batch, K, N) &gt; (batch, M, N)</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_axis-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.broadcast_axis-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.broadcast_axis</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_axis(src, axis, size)
</code></pre>

<p>Broadcast data in the given axis to the given size. The original size of the broadcasting axis must be 1.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>axis::Shape(tuple), optional, default=()</code>: The axes to perform the broadcasting.</li>
<li><code>size::Shape(tuple), optional, default=()</code>: Target sizes of the broadcasting axes.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1119' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_div-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.broadcast_div-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.broadcast_div</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_div(lhs, rhs)
</code></pre>

<p>lhs divide rhs with broadcast</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_minus-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.broadcast_minus-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.broadcast_minus</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_minus(lhs, rhs)
</code></pre>

<p>lhs minus rhs with broadcast</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_mul-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.broadcast_mul-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.broadcast_mul</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_mul(lhs, rhs)
</code></pre>

<p>lhs multiple rhs with broadcast</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_plus-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.broadcast_plus-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.broadcast_plus</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_plus(lhs, rhs)
</code></pre>

<p>lhs add rhs with broadcast</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_power-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.broadcast_power-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.broadcast_power</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_power(lhs, rhs)
</code></pre>

<p>lhs power rhs with broadcast</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_to-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.broadcast_to-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.broadcast_to</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_to(src, shape)
</code></pre>

<p>Broadcast data to the target shape. The original size of the broadcasting axis must be 1.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>shape::Shape(tuple), optional, default=()</code>: The shape of the desired array. We can set the dim to zero if it's same as the original. E.g <code>A = broadcast_to(B, shape=(10, 0, 0))</code> has the same meaning as <code>A = broadcast_axis(B, axis=0, size=10)</code>.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.choose_element_0index-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.choose_element_0index-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.choose_element_0index</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>choose_element_0index(lhs, rhs)
</code></pre>

<p>Choose one element from each line(row for python, column for R/Julia) in lhs according to index indicated by rhs. This function assume rhs uses 0-based index.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand to the function.</li>
<li><code>rhs::NDArray</code>: Right operand to the function.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.clip-Tuple{MXNet.mx.NDArray,Real,Real,MXNet.mx.NDArray}' href='#MXNet.mx.clip-Tuple{MXNet.mx.NDArray,Real,Real,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.clip</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>clip(src, a_min, a_max)
</code></pre>

<p>Clip ndarray elements to range (a_min, a_max)</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input</li>
<li><code>a_min::real_t</code>: Minimum value</li>
<li><code>a_max::real_t</code>: Maximum value</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1119' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.context-Tuple{MXNet.mx.NDArray}' href='#MXNet.mx.context-Tuple{MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.context</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>context(arr :: NDArray)
</code></pre>

<p>Get the context that this <code>NDArray</code> lives on.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L110-L114' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.crop-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.crop-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.crop</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>crop(src, begin, end)
</code></pre>

<p>Crop the input tensor and return a new one.</p>
<p><strong>Requirements</strong></p>
<ul>
<li>the input and output (if explicitly given) are of the same data type, and on the same device.</li>
</ul>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>begin::Shape(tuple), required</code>: starting coordinates</li>
<li><code>end::Shape(tuple), required</code>: ending coordinates</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1125' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.div_from!-Tuple{MXNet.mx.NDArray,Union{MXNet.mx.NDArray,Real}}' href='#MXNet.mx.div_from!-Tuple{MXNet.mx.NDArray,Union{MXNet.mx.NDArray,Real}}'>#</a>
<strong><code>MXNet.mx.div_from!</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>div_from!(dst :: NDArray, arg :: Union{Real, NDArray})
</code></pre>

<p>Elementwise divide a scalar or an <code>NDArray</code> of the same shape from <code>dst</code>. Inplace updating.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L637-L641' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.element_mask-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.element_mask-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.element_mask</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>element_mask(lhs, rhs)
</code></pre>

<p>rhs elmentwise mask lhs with broadcast</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.empty-Tuple{Tuple{Vararg{Int64,N}}}' href='#MXNet.mx.empty-Tuple{Tuple{Vararg{Int64,N}}}'>#</a>
<strong><code>MXNet.mx.empty</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>empty(shape :: Tuple, ctx :: Context)
empty(shape :: Tuple)
empty(dim1, dim2, ...)
</code></pre>

<p>Allocate memory for an uninitialized <code>NDArray</code> with specific shape of type Float32.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L141-L147' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.empty-Tuple{Type{T<:Union{Float16,Float32,Float64,Int32,UInt8}},Tuple{Vararg{Int64,N}}}' href='#MXNet.mx.empty-Tuple{Type{T<:Union{Float16,Float32,Float64,Int32,UInt8}},Tuple{Vararg{Int64,N}}}'>#</a>
<strong><code>MXNet.mx.empty</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>empty(DType, shape :: Tuple, ctx :: Context)
empty(DType, shape :: Tuple)
empty(DType, dim1, dim2, ...)
</code></pre>

<p>Allocate memory for an uninitialized <code>NDArray</code> with a specified type.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L124-L130' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.expand_dims-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.expand_dims-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.expand_dims</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>expand_dims(src, axis)
</code></pre>

<p>Expand the shape of array by inserting a new axis.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>axis::int (non-negative), required</code>: Position (amongst axes) where new axis is to be inserted.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.fill_element_0index-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.fill_element_0index-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.fill_element_0index</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>fill_element_0index(lhs, mhs, rhs)
</code></pre>

<p>Fill one element of each line(row for python, column for R/Julia) in lhs according to index indicated by rhs and values indicated by mhs. This function assume rhs uses 0-based index.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand to the function.</li>
<li><code>mhs::NDArray</code>: Middle operand to the function.</li>
<li><code>rhs::NDArray</code>: Right operand to the function.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1119' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.flip-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.flip-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.flip</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>flip(src, axis)
</code></pre>

<p>Flip the input matrix along axis and return a new one</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>axis::int, required</code>: The dimension to flip</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.is_shared-Tuple{Array,MXNet.mx.NDArray}' href='#MXNet.mx.is_shared-Tuple{Array,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.is_shared</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>is_shared(j_arr, arr)
</code></pre>

<p>Test whether <code>j_arr</code> is sharing data with <code>arr</code>.</p>
<p><strong>Arguments:</strong></p>
<ul>
<li>Array j_arr: the Julia Array.</li>
<li>NDArray arr: the <code>NDArray</code>.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L823-L831' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.load-Tuple{AbstractString,Type{MXNet.mx.NDArray}}' href='#MXNet.mx.load-Tuple{AbstractString,Type{MXNet.mx.NDArray}}'>#</a>
<strong><code>MXNet.mx.load</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>load(filename, ::Type{NDArray})
</code></pre>

<p>Load NDArrays from binary file.</p>
<p><strong>Arguments:</strong></p>
<ul>
<li><code>filename::String</code>: the path of the file to load. It could be S3 or HDFS address.</li>
</ul>
<p>Returns either <code>Dict{Symbol, NDArray}</code> or <code>Vector{NDArray}</code>.</p>
<p><code>filename</code> can point to <code>s3</code> or <code>hdfs</code> resources if the <code>libmxnet</code> is built with the corresponding components enabled. Examples:</p>
<ul>
<li><code>s3://my-bucket/path/my-s3-ndarray</code></li>
<li><code>hdfs://my-bucket/path/my-hdfs-ndarray</code></li>
<li><code>/path-to/my-local-ndarray</code></li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L845-L860' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.max_axis-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.max_axis-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.max_axis</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>max_axis(src, axis, keepdims)
</code></pre>

<p>(Depreciated! Use max instead!) Take max of the src in the given axis and returns a NDArray. Follows numpy semantics.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>axis::Shape(tuple), optional, default=()</code>: Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.</li>
<li><code>keepdims::boolean, optional, default=False</code>: Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1119' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.min_axis-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.min_axis-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.min_axis</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>min_axis(src, axis, keepdims)
</code></pre>

<p>(Depreciated! Use min instead!) Take min of the src in the given axis and returns a NDArray. Follows numpy semantics.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>axis::Shape(tuple), optional, default=()</code>: Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.</li>
<li><code>keepdims::boolean, optional, default=False</code>: Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1119' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.mul_to!-Tuple{MXNet.mx.NDArray,Union{MXNet.mx.NDArray,Real}}' href='#MXNet.mx.mul_to!-Tuple{MXNet.mx.NDArray,Union{MXNet.mx.NDArray,Real}}'>#</a>
<strong><code>MXNet.mx.mul_to!</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>mul_to!(dst :: NDArray, arg :: Union{Real, NDArray})
</code></pre>

<p>Elementwise multiplication into <code>dst</code> of either a scalar or an <code>NDArray</code> of the same shape. Inplace updating.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L592-L597' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.ones-Tuple{Tuple{Vararg{Int64,N}}}' href='#MXNet.mx.ones-Tuple{Tuple{Vararg{Int64,N}}}'>#</a>
<strong><code>MXNet.mx.ones</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>ones(shape :: Tuple, ctx :: Context)
ones(shape :: Tuple)
ones(dim1, dim2, ...)
</code></pre>

<p>Create an <code>NDArray</code> with specific shape and initialize with 1.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L215-L221' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.ones-Tuple{Type{T<:Union{Float16,Float32,Float64,Int32,UInt8}},Tuple{Vararg{Int64,N}}}' href='#MXNet.mx.ones-Tuple{Type{T<:Union{Float16,Float32,Float64,Int32,UInt8}},Tuple{Vararg{Int64,N}}}'>#</a>
<strong><code>MXNet.mx.ones</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>ones(DType, shape :: Tuple, ctx :: Context)
ones(DType, shape :: Tuple)
ones(DType, dim1, dim2, ...)
</code></pre>

<p>Create an <code>NDArray</code> with specific shape &amp; type, and initialize with 1.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L196-L202' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.rsqrt-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.rsqrt-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.rsqrt</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>rsqrt(src)
</code></pre>

<p>Take rsqrt of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.save-Tuple{String,MXNet.mx.NDArray}' href='#MXNet.mx.save-Tuple{String,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.save</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>save(filename :: AbstractString, data)
</code></pre>

<p>Save NDarrays to binary file. Filename could be S3 or HDFS address, if <code>libmxnet</code> is built with corresponding support (see <code>load</code>).</p>
<ul>
<li><code>filename::String</code>: path to the binary file to write to.</li>
<li><code>data</code>: data to save to file. Data can be a<code>NDArray</code>, a <code>Vector{NDArray}</code>, or a <code>Dict{Base.Symbol, NDArray}</code>.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L879-L887' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.slice_axis-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.slice_axis-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.slice_axis</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>slice_axis(src, axis, begin, end)
</code></pre>

<p>Slice the input along certain axis and return a sliced array.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>axis::int, required</code>: The axis to be sliced</li>
<li><code>begin::int, required</code>: The beginning index to be sliced</li>
<li><code>end::int, required</code>: The end index to be sliced</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1121' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.smooth_l1-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.smooth_l1-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.smooth_l1</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>smooth_l1(src)
</code></pre>

<p>Calculate Smooth L1 Loss(lhs, scalar)</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.softmax_cross_entropy-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.softmax_cross_entropy-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.softmax_cross_entropy</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>softmax_cross_entropy(lhs, rhs)
</code></pre>

<p>Calculate cross_entropy(lhs, one_hot(rhs))</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::NDArray</code>: Left operand  to the function</li>
<li><code>rhs::NDArray</code>: Right operand to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1117' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.square-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.square-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.square</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>square(src)
</code></pre>

<p>Take square of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1115' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.sub_from!-Tuple{MXNet.mx.NDArray,Union{MXNet.mx.NDArray,Real}}' href='#MXNet.mx.sub_from!-Tuple{MXNet.mx.NDArray,Union{MXNet.mx.NDArray,Real}}'>#</a>
<strong><code>MXNet.mx.sub_from!</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>sub_from!(dst :: NDArray, args :: Union{Real, NDArray}...)
</code></pre>

<p>Subtract a bunch of arguments from <code>dst</code>. Inplace updating.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L548-L552' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.sum_axis-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}' href='#MXNet.mx.sum_axis-Tuple{MXNet.mx.NDArray,MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.sum_axis</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>sum_axis(src, axis, keepdims)
</code></pre>

<p>(Depreciated! Use sum instead!) Take sum of the src in the given axis and returns a NDArray. Follows numpy semantics.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::NDArray</code>: Source input to the function</li>
<li><code>axis::Shape(tuple), optional, default=()</code>: Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.</li>
<li><code>keepdims::boolean, optional, default=False</code>: Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L1108-L1119' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.try_get_shared-Tuple{MXNet.mx.NDArray}' href='#MXNet.mx.try_get_shared-Tuple{MXNet.mx.NDArray}'>#</a>
<strong><code>MXNet.mx.try_get_shared</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>try_get_shared(arr)
</code></pre>

<p>Try to create a Julia array by sharing the data with the underlying <code>NDArray</code>.</p>
<p><strong>Arguments:</strong></p>
<ul>
<li><code>arr::NDArray</code>: the array to be shared.</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned array does not guarantee to share data with the underlying <code>NDArray</code>. In particular, data sharing is possible only when the <code>NDArray</code> lives on CPU.</p>
</div>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L801-L812' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.zeros-Tuple{Tuple{Vararg{Int64,N}}}' href='#MXNet.mx.zeros-Tuple{Tuple{Vararg{Int64,N}}}'>#</a>
<strong><code>MXNet.mx.zeros</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>zeros(shape :: Tuple, ctx :: Context)
zeros(shape :: Tuple)
zeros(dim1, dim2, ...)
</code></pre>

<p>Create zero-ed <code>NDArray</code> with specific shape.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L177-L183' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.zeros-Tuple{Type{T<:Union{Float16,Float32,Float64,Int32,UInt8}},Tuple{Vararg{Int64,N}}}' href='#MXNet.mx.zeros-Tuple{Type{T<:Union{Float16,Float32,Float64,Int32,UInt8}},Tuple{Vararg{Int64,N}}}'>#</a>
<strong><code>MXNet.mx.zeros</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>zeros(DType, shape :: Tuple, ctx :: Context)
zeros(DType, shape :: Tuple)
zeros(DType, dim1, dim2, ...)
</code></pre>

<p>Create zero-ed <code>NDArray</code> with specific shape and type</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L158-L164' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.@inplace-Tuple{Any}' href='#MXNet.mx.@inplace-Tuple{Any}'>#</a>
<strong><code>MXNet.mx.@inplace</code></strong> &mdash; <em>Macro</em>.</p>
<pre><code>@inplace
</code></pre>

<p>Julia does not support re-definiton of <code>+=</code> operator (like <code>__iadd__</code> in python), When one write <code>a += b</code>, it gets translated to <code>a = a+b</code>. <code>a+b</code> will allocate new memory for the results, and the newly allocated <code>NDArray</code> object is then assigned back to a, while the original contents in a is discarded. This is very inefficient when we want to do inplace update.</p>
<p>This macro is a simple utility to implement this behavior. Write</p>
<pre><code class="julia">  @mx.inplace a += b
</code></pre>

<p>will translate into</p>
<pre><code class="julia">  mx.add_to!(a, b)
</code></pre>

<p>which will do inplace adding of the contents of <code>b</code> into <code>a</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L470-L492' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.@nd_as_jl-Tuple{Vararg{Any,N}}' href='#MXNet.mx.@nd_as_jl-Tuple{Vararg{Any,N}}'>#</a>
<strong><code>MXNet.mx.@nd_as_jl</code></strong> &mdash; <em>Macro</em>.</p>
<p><strong>Manipulating as Julia Arrays</strong></p>
<pre><code>@nd_as_jl(captures..., statement)
</code></pre>

<p>A convenient macro that allows to operate <code>NDArray</code> as Julia Arrays. For example,</p>
<pre><code class="julia">  x = mx.zeros(3,4)
  y = mx.ones(3,4)
  z = mx.zeros((3,4), mx.gpu())

  @mx.nd_as_jl ro=(x,y) rw=z begin
    # now x, y, z are just ordinary Julia Arrays
    z[:,1] = y[:,2]
    z[:,2] = 5
  end
</code></pre>

<p>Under the hood, the macro convert all the declared captures from <code>NDArray</code> into Julia Arrays, by using <code>try_get_shared</code>. And automatically commit the modifications back into the <code>NDArray</code> that is declared as <code>rw</code>. This is useful for fast prototyping and when implement non-critical computations, such as <code>AbstractEvalMetric</code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
</div>
<ul>
<li>Multiple <code>rw</code> and / or <code>ro</code> capture declaration could be made.</li>
<li>The macro does <strong>not</strong> check to make sure that <code>ro</code> captures are not modified. If the original <code>NDArray</code> lives in CPU memory, then it is very likely the corresponding Julia Array shares data with the <code>NDArray</code>, so modifying the Julia Array will also modify the underlying <code>NDArray</code>.</li>
<li>More importantly, since the <code>NDArray</code> is asynchronized, we will wait for <em>writing</em> for <code>rw</code> variables but wait only for <em>reading</em> in <code>ro</code> variables. If we write into those <code>ro</code> variables, <strong>and</strong> if the memory is shared, racing condition might happen, and the behavior is undefined.</li>
<li>When an <code>NDArray</code> is declared to be captured as <code>rw</code>, its contents is always sync back in the end.</li>
<li>The execution results of the expanded macro is always <code>nothing</code>.</li>
<li>The statements are wrapped in a <code>let</code>, thus locally introduced new variables will not be available after the statements. So you will need to declare the variables before calling the macro if needed.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/ndarray.jl#L672-L713' class='documenter-source'>source</a><br></p>
          <aside class="copyright" role="note">
            
            Documentation built with
            <a href="http://www.mkdocs.org" target="_blank">MkDocs</a>
            using the
            <a href="http://squidfunk.github.io/mkdocs-material/" target="_blank">
              Material
            </a>
            theme.
          </aside>
          
            <footer class="footer">
              
  <nav class="pagination" aria-label="Footer">
    <div class="previous">
      
        <a href="../io/" title="Data Providers">
          <span class="direction">
            Previous
          </span>
          <div class="page">
            <div class="button button-previous" role="button" aria-label="Previous">
              <i class="icon icon-back"></i>
            </div>
            <div class="stretch">
              <div class="title">
                Data Providers
              </div>
            </div>
          </div>
        </a>
      
    </div>
    <div class="next">
      
        <a href="../symbolic-node/" title="Symbolic API">
          <span class="direction">
            Next
          </span>
          <div class="page">
            <div class="stretch">
              <div class="title">
                Symbolic API
              </div>
            </div>
            <div class="button button-next" role="button" aria-label="Next">
              <i class="icon icon-forward"></i>
            </div>
          </div>
        </a>
      
    </div>
  </nav>

            </footer>
          
        </div>
      </article>
      <div class="results" role="status" aria-live="polite">
        <div class="scrollable">
          <div class="wrapper">
            <div class="meta"></div>
            <div class="list"></div>
          </div>
        </div>
      </div>
    </main>
    <script>
      var base_url = '../..';
      var repo_id  = 'dmlc/MXNet.jl';
    </script>
    <script src="../../assets/javascripts/application-997097ee0c.js"></script>
    
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.jl?config=TeX-AMS-MML_HTMLorMML"></script>
    
      <script src="../../assets/mathjaxhelper.js"></script>
    
    
  </body>
</html>