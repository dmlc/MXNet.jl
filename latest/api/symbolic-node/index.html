<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="no-js ie6"><![endif]-->
<!--[if IE 7 ]><html class="no-js ie7"><![endif]-->
<!--[if IE 8 ]><html class="no-js ie8"><![endif]-->
<!--[if IE 9 ]><html class="no-js ie9"><![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html class="no-js"> <!--<![endif]-->
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1">
    
      
        <title>Symbolic API - MXNet.jl</title>
      
      
      
      
    
    <meta property="og:url" content="None">
    <meta property="og:title" content="MXNet.jl">
    <meta property="og:image" content="None/../../">
    <meta name="apple-mobile-web-app-title" content="MXNet.jl">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    
    
    <link rel="shortcut icon" type="image/x-icon" href="../../assets/images/favicon-e565ddfa3b.ico">
    <link rel="icon" type="image/x-icon" href="../../assets/images/favicon-e565ddfa3b.ico">
    <style>
      @font-face {
      	font-family: 'Icon';
      	src: url('../../assets/fonts/icon.eot?52m981');
      	src: url('../../assets/fonts/icon.eot?#iefix52m981')
               format('embedded-opentype'),
      		   url('../../assets/fonts/icon.woff?52m981')
               format('woff'),
      		   url('../../assets/fonts/icon.ttf?52m981')
               format('truetype'),
      		   url('../../assets/fonts/icon.svg?52m981#icon')
               format('svg');
      	font-weight: normal;
      	font-style: normal;
      }
    </style>
    <link rel="stylesheet" href="../../assets/stylesheets/application-a422ff04cc.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/palettes-05ab2406df.css">
    
    
      
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,700|Ubuntu+Mono">
      <style>
        body, input {
          font-family: 'Ubuntu', Helvetica, Arial, sans-serif;
        }
        pre, code {
          font-family: 'Ubuntu Mono', 'Courier New', 'Courier', monospace;
        }
      </style>
    
    
      <link rel="stylesheet" href="../../assets/Documenter.css">
    
    <script src="../../assets/javascripts/modernizr-4ab42b99fd.js"></script>
    
  </head>
  
  
  
  <body class="palette-primary-indigo palette-accent-blue">
    
      
      
    
    <div class="backdrop">
      <div class="backdrop-paper"></div>
    </div>
    <input class="toggle" type="checkbox" id="toggle-drawer">
    <input class="toggle" type="checkbox" id="toggle-search">
    <label class="toggle-button overlay" for="toggle-drawer"></label>
    <header class="header">
      <nav aria-label="Header">
  <div class="bar default">
    <div class="button button-menu" role="button" aria-label="Menu">
      <label class="toggle-button icon icon-menu" for="toggle-drawer">
        <span></span>
      </label>
    </div>
    <div class="stretch">
      <div class="title">
        
          <span class="path">
            
              
                API Documentation <i class="icon icon-link"></i>
              
            
          </span>
        
        Symbolic API
      </div>
    </div>
    
    
    <div class="button button-search" role="button" aria-label="Search">
      <label class="toggle-button icon icon-search" title="Search" for="toggle-search"></label>
    </div>
  </div>
  <div class="bar search">
    <div class="button button-close" role="button" aria-label="Close">
      <label class="toggle-button icon icon-back" for="toggle-search"></label>
    </div>
    <div class="stretch">
      <div class="field">
        <input class="query" type="text" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck>
      </div>
    </div>
    <div class="button button-reset" role="button" aria-label="Search">
      <button class="toggle-button icon icon-close" id="reset-search"></button>
    </div>
  </div>
</nav>
    </header>
    <main class="main">
      
      <div class="drawer">
        <nav aria-label="Navigation">
  
  <a href="https://github.com/dmlc/MXNet.jl" class="project">
    <div class="banner">
      
      <div class="name">
        <strong>
          MXNet.jl
          <span class="version">
            
          </span>
        </strong>
        
          <br>
          dmlc/MXNet.jl
        
      </div>
    </div>
  </a>
  <div class="scrollable">
    <div class="wrapper">
      
        <ul class="repo">
          <li class="repo-download">
            
            <a href="https://github.com/dmlc/MXNet.jl/archive/master.zip" target="_blank" title="Download" data-action="download">
              <i class="icon icon-download"></i> Download
            </a>
          </li>
          <li class="repo-stars">
            <a href="https://github.com/dmlc/MXNet.jl/stargazers" target="_blank" title="Stargazers" data-action="star">
              <i class="icon icon-star"></i> Stars
              <span class="count">&ndash;</span>
            </a>
          </li>
        </ul>
        <hr>
      
      <div class="toc">
        <ul>
          
            
  <li>
    <a class="" title="Home" href="../..">
      Home
    </a>
    
  </li>

          
            
  <li>
    <span class="section">Tutorial</span>
    <ul>
      
        
  <li>
    <a class="" title="Digit Recognition on MNIST" href="../../tutorial/mnist/">
      Digit Recognition on MNIST
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Generating Random Sentence with LSTM RNN" href="../../tutorial/char-lstm/">
      Generating Random Sentence with LSTM RNN
    </a>
    
  </li>

      
    </ul>
  </li>

          
            
  <li>
    <span class="section">User Guide</span>
    <ul>
      
        
  <li>
    <a class="" title="Installation Guide" href="../../user-guide/install/">
      Installation Guide
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Overview" href="../../user-guide/overview/">
      Overview
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="FAQ" href="../../user-guide/faq/">
      FAQ
    </a>
    
  </li>

      
    </ul>
  </li>

          
            
  <li>
    <span class="section">API Documentation</span>
    <ul>
      
        
  <li>
    <a class="" title="Context" href="../context/">
      Context
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Models" href="../model/">
      Models
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Initializers" href="../initializer/">
      Initializers
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Optimizers" href="../optimizer/">
      Optimizers
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Callbacks in training" href="../callback/">
      Callbacks in training
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Evaluation Metrics" href="../metric/">
      Evaluation Metrics
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Data Providers" href="../io/">
      Data Providers
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="NDArray API" href="../ndarray/">
      NDArray API
    </a>
    
  </li>

      
        
  <li>
    <a class="current" title="Symbolic API" href="./">
      Symbolic API
    </a>
    
      
        
      
      
    
  </li>

      
        
  <li>
    <a class="" title="Neural Networks Factory" href="../nn-factory/">
      Neural Networks Factory
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Executor" href="../executor/">
      Executor
    </a>
    
  </li>

      
        
  <li>
    <a class="" title="Network Visualization" href="../visualize/">
      Network Visualization
    </a>
    
  </li>

      
    </ul>
  </li>

          
        </ul>
        
      </div>
    </div>
  </div>
</nav>
      </div>
      <article class="article">
        <div class="wrapper">
          
          <p><a id='Symbolic-API-1'></a></p>
<h1 id="symbolic-api">Symbolic API</h1>
<p><a id='MXNet.mx.SymbolicNode' href='#MXNet.mx.SymbolicNode'>#</a>
<strong><code>MXNet.mx.SymbolicNode</code></strong> &mdash; <em>Type</em>.</p>
<pre><code>SymbolicNode
</code></pre>

<p>SymbolicNode is the basic building block of the symbolic graph in MXNet.jl.</p>
<pre><code>(self :: SymbolicNode)(args :: SymbolicNode...)
(self :: SymbolicNode)(; kwargs...)
</code></pre>

<p>Make a new node by composing <code>self</code> with <code>args</code>. Or the arguments can be specified using keyword arguments.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L1-L11' class='documenter-source'>source</a><br></p>
<p><a id='Base.LinAlg.dot-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.LinAlg.dot-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.LinAlg.dot</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>dot(lhs, rhs)
</code></pre>

<p>Calculate dot product of two matrices or two vectors</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='Base.abs-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.abs-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.abs</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>abs(src)
</code></pre>

<p>Take absolute value of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='Base.ceil-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.ceil-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.ceil</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>ceil(src)
</code></pre>

<p>Take ceil value of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='Base.copy-Tuple{MXNet.mx.SymbolicNode}' href='#Base.copy-Tuple{MXNet.mx.SymbolicNode}'>#</a>
<strong><code>Base.copy</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>copy(self :: SymbolicNode)
</code></pre>

<p>Make a copy of a SymbolicNode. The same as making a deep copy.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L32-L36' class='documenter-source'>source</a><br></p>
<p><a id='Base.cos-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.cos-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.cos</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>cos(src)
</code></pre>

<p>Take cos of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='Base.deepcopy-Tuple{MXNet.mx.SymbolicNode}' href='#Base.deepcopy-Tuple{MXNet.mx.SymbolicNode}'>#</a>
<strong><code>Base.deepcopy</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>deepcopy(self :: SymbolicNode)
</code></pre>

<p>Make a deep copy of a SymbolicNode.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L21-L25' class='documenter-source'>source</a><br></p>
<p><a id='Base.exp-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.exp-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.exp</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>exp(src)
</code></pre>

<p>Take exp of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='Base.floor-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.floor-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.floor</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>floor(src)
</code></pre>

<p>Take floor value of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='Base.getindex-Tuple{MXNet.mx.SymbolicNode,Union{AbstractString,Symbol}}' href='#Base.getindex-Tuple{MXNet.mx.SymbolicNode,Union{AbstractString,Symbol}}'>#</a>
<strong><code>Base.getindex</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>getindex(self :: SymbolicNode, idx :: Union{Int, Base.Symbol, AbstractString})
</code></pre>

<p>Get a node representing the specified output of this node. The index could be a symbol or string indicating the name of the output, or a 1-based integer indicating the index, as in the list of <a href="./#MXNet.mx.list_outputs-Tuple{MXNet.mx.SymbolicNode}"><code>list_outputs</code></a>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L396-L402' class='documenter-source'>source</a><br></p>
<p><a id='Base.log-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.log-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.log</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>log(src)
</code></pre>

<p>Take log of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='Base.round-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.round-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.round</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>round(src)
</code></pre>

<p>Take round value of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='Base.sign-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.sign-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.sign</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>sign(src)
</code></pre>

<p>Take sign value of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='Base.sin-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.sin-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.sin</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>sin(src)
</code></pre>

<p>Take sin of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='Base.sqrt-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.sqrt-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.sqrt</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>sqrt(src)
</code></pre>

<p>Take sqrt of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='Base.sum-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.sum-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.sum</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>sum(src, axis, keepdims)
</code></pre>

<p>Take sum of the src in the given axis and returns a NDArray. Follows numpy semantics.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>axis::Shape(tuple), optional, default=()</code>: Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.</li>
<li><code>keepdims::boolean, optional, default=False</code>: Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L772' class='documenter-source'>source</a><br></p>
<p><a id='Base.transpose-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#Base.transpose-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>Base.transpose</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>transpose(src, axes)
</code></pre>

<p>Transpose the input matrix and return a new one</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>axes::Shape(tuple), optional, default=()</code>: Target axis order. By default the axes will be inverted.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Activation-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Activation-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Activation</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Activation(act_type)
</code></pre>

<p>Elementwise activation function.</p>
<p>The following activation types are supported (operations are applied elementwisely to each scalar of the input tensor):</p>
<ul>
<li><code>relu</code>: Rectified Linear Unit, <code>y = max(x, 0)</code></li>
<li><code>sigmoid</code>: <code>y = 1 / (1 + exp(-x))</code></li>
<li><code>tanh</code>: Hyperbolic tangent, <code>y = (exp(x) - exp(-x)) / (exp(x) + exp(-x))</code></li>
<li><code>softrelu</code>: Soft ReLU, or SoftPlus, <code>y = log(1 + exp(x))</code></li>
</ul>
<p>See <code>LeakyReLU</code> for other activations with parameters.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>act_type::{'relu', 'sigmoid', 'softrelu', 'tanh'}, required</code>: Activation function to be applied.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L779' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.BatchNorm-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.BatchNorm-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.BatchNorm</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>BatchNorm(data, eps, momentum, fix_gamma, use_global_stats)
</code></pre>

<p>Apply batch normalization to input.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to batch normalization</li>
<li><code>eps::float, optional, default=0.001</code>: Epsilon to prevent div 0</li>
<li><code>momentum::float, optional, default=0.9</code>: Momentum for moving average</li>
<li><code>fix_gamma::boolean, optional, default=True</code>: Fix gamma while training</li>
<li><code>use_global_stats::boolean, optional, default=False</code>: Whether use global moving statistics instead of local batch-norm. This will force change batch-norm into a scale shift operator.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L776' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.BlockGrad-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.BlockGrad-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.BlockGrad</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>BlockGrad(data)
</code></pre>

<p>Get output from a symbol and pass 0 gradient back</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Cast-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Cast-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Cast</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Cast(data, dtype)
</code></pre>

<p>Cast array to a different data type.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to cast function.</li>
<li><code>dtype::{'float16', 'float32', 'float64', 'int32', 'uint8'}, required</code>: Target data type.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Concat-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Concat-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Concat</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Concat(data, num_args, dim)
</code></pre>

<p>Perform a feature concat on channel dim (defaut is 1) over all</p>
<p>This function support variable length positional <code>SymbolicNode</code> inputs.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode[]</code>: List of tensors to concatenate</li>
<li><code>num_args::int, required</code>: Number of inputs to be concated.</li>
<li><code>dim::int, optional, default='1'</code>: the dimension to be concated.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L774' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Convolution-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Convolution-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Convolution</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Convolution(data, weight, bias, kernel, stride, dilate, pad, num_filter, num_group, workspace, no_bias, cudnn_tune, cudnn_off)
</code></pre>

<p>Apply convolution to input then add a bias.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to the ConvolutionOp.</li>
<li><code>weight::SymbolicNode</code>: Weight matrix.</li>
<li><code>bias::SymbolicNode</code>: Bias parameter.</li>
<li><code>kernel::Shape(tuple), required</code>: convolution kernel size: (y, x) or (d, y, x)</li>
<li><code>stride::Shape(tuple), optional, default=(1,1)</code>: convolution stride: (y, x) or (d, y, x)</li>
<li><code>dilate::Shape(tuple), optional, default=(1,1)</code>: convolution dilate: (y, x)</li>
<li><code>pad::Shape(tuple), optional, default=(0,0)</code>: pad for convolution: (y, x) or (d, y, x)</li>
<li><code>num_filter::int (non-negative), required</code>: convolution filter(channel) number</li>
<li><code>num_group::int (non-negative), optional, default=1</code>: Number of groups partition. This option is not supported by CuDNN, you can use SliceChannel to num_group,apply convolution and concat instead to achieve the same need.</li>
<li><code>workspace::long (non-negative), optional, default=1024</code>: Tmp workspace for convolution (MB).</li>
<li><code>no_bias::boolean, optional, default=False</code>: Whether to disable bias parameter.</li>
<li><code>cudnn_tune::{'fastest', 'limited_workspace', 'off'},optional, default='off'</code>: Whether to find convolution algo by running performance test.Leads to higher startup time but may give better speed.auto tune is turned off by default.Set environment varialbe MXNET_CUDNN_AUTOTUNE_DEFAULT=1 to turn on by default.</li>
<li><code>cudnn_off::boolean, optional, default=False</code>: Turn off cudnn.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L792' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Correlation-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Correlation-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Correlation</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Correlation(data1, data2, kernel_size, max_displacement, stride1, stride2, pad_size, is_multiply)
</code></pre>

<p>Apply correlation to inputs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data1::SymbolicNode</code>: Input data1 to the correlation.</li>
<li><code>data2::SymbolicNode</code>: Input data2 to the correlation.</li>
<li><code>kernel_size::int (non-negative), optional, default=1</code>: kernel size for Correlation must be an odd number</li>
<li><code>max_displacement::int (non-negative), optional, default=1</code>: Max displacement of Correlation</li>
<li><code>stride1::int (non-negative), optional, default=1</code>: stride1 quantize data1 globally</li>
<li><code>stride2::int (non-negative), optional, default=1</code>: stride2 quantize data2 within the neighborhood centered around data1</li>
<li><code>pad_size::int (non-negative), optional, default=0</code>: pad for Correlation</li>
<li><code>is_multiply::boolean, optional, default=True</code>: operation type is either multiplication or subduction</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L782' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Crop-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Crop-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Crop</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Crop(data, num_args, offset, h_w, center_crop)
</code></pre>

<p>Crop the 2nd and 3rd dim of input data, with the corresponding size of h_w or with width and height of the second input symbol, i.e., with one input, we need h_w to specify the crop height and width, otherwise the second input symbol's size will be used</p>
<p>This function support variable length positional <code>SymbolicNode</code> inputs.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode or SymbolicNode[]</code>: Tensor or List of Tensors, the second input will be used as crop_like shape reference</li>
<li><code>num_args::int, required</code>: Number of inputs for crop, if equals one, then we will use the h_wfor crop height and width, else if equals two, then we will use the heightand width of the second input symbol, we name crop_like here</li>
<li><code>offset::Shape(tuple), optional, default=(0,0)</code>: crop offset coordinate: (y, x)</li>
<li><code>h_w::Shape(tuple), optional, default=(0,0)</code>: crop height and weight: (h, w)</li>
<li><code>center_crop::boolean, optional, default=False</code>: If set to true, then it will use be the center_crop,or it will crop using the shape of crop_like</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L778' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Custom-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Custom-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Custom</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Custom(op_type)
</code></pre>

<p>Custom operator implemented in frontend.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>op_type::string</code>: Type of custom operator. Must be registered first.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Deconvolution-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Deconvolution-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Deconvolution</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Deconvolution(data, weight, bias, kernel, stride, pad, adj, target_shape, num_filter, num_group, workspace, no_bias)
</code></pre>

<p>Apply deconvolution to input then add a bias.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to the DeconvolutionOp.</li>
<li><code>weight::SymbolicNode</code>: Weight matrix.</li>
<li><code>bias::SymbolicNode</code>: Bias parameter.</li>
<li><code>kernel::Shape(tuple), required</code>: deconvolution kernel size: (y, x)</li>
<li><code>stride::Shape(tuple), optional, default=(1,1)</code>: deconvolution stride: (y, x)</li>
<li><code>pad::Shape(tuple), optional, default=(0,0)</code>: pad for deconvolution: (y, x), a good number is : (kernel-1)/2, if target_shape set, pad will be ignored and will be computed automatically</li>
<li><code>adj::Shape(tuple), optional, default=(0,0)</code>: adjustment for output shape: (y, x), if target_shape set, adj will be ignored and will be computed automatically</li>
<li><code>target_shape::Shape(tuple), optional, default=(0,0)</code>: output shape with targe shape : (y, x)</li>
<li><code>num_filter::int (non-negative), required</code>: deconvolution filter(channel) number</li>
<li><code>num_group::int (non-negative), optional, default=1</code>: number of groups partition</li>
<li><code>workspace::long (non-negative), optional, default=512</code>: Tmp workspace for deconvolution (MB)</li>
<li><code>no_bias::boolean, optional, default=True</code>: Whether to disable bias parameter.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L790' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Dropout-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Dropout-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Dropout</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Dropout(data, p)
</code></pre>

<p>Apply dropout to input. During training, each element of the input is randomly set to zero with probability p. And then the whole tensor is rescaled by 1/(1-p) to keep the expectation the same as before applying dropout. During the test time, this behaves as an identity map.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to dropout.</li>
<li><code>p::float, optional, default=0.5</code>: Fraction of the input that gets dropped out at training time</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L774' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.ElementWiseSum-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.ElementWiseSum-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.ElementWiseSum</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>ElementWiseSum(num_args)
</code></pre>

<p>Perform an elementwise sum over all the inputs.</p>
<p>This function support variable length positional <code>SymbolicNode</code> inputs.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>num_args::int, required</code>: Number of inputs to be summed.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Embedding-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Embedding-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Embedding</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Embedding(data, weight, input_dim, output_dim)
</code></pre>

<p>Map integer index to vector representations (embeddings). Those embeddings are learnable parameters. For a input of shape <code>(d1, ..., dK)</code>, the output shape is <code>(d1, ..., dK, output_dim)</code>. All the input values should be integers in the range <code>[0, input_dim)</code>.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to the EmbeddingOp.</li>
<li><code>weight::SymbolicNode</code>: Embedding weight matrix.</li>
<li><code>input_dim::int, required</code>: vocabulary size of the input indices.</li>
<li><code>output_dim::int, required</code>: dimension of the embedding vectors.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L777' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Flatten-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Flatten-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Flatten</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Flatten(data)
</code></pre>

<p>Flatten input into 2D by collapsing all the higher dimensions. A (d1, d2, ..., dK) tensor is flatten to (d1, d2<em> ... </em>dK) matrix.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to flatten.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L769' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.FullyConnected-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.FullyConnected-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.FullyConnected</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>FullyConnected(data, weight, bias, num_hidden, no_bias)
</code></pre>

<p>Apply matrix multiplication to input then add a bias. It maps the input of shape <code>(batch_size, input_dim)</code> to the shape of <code>(batch_size, num_hidden)</code>. Learnable parameters include the weights of the linear transform and an optional bias vector.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to the FullyConnectedOp.</li>
<li><code>weight::SymbolicNode</code>: Weight matrix.</li>
<li><code>bias::SymbolicNode</code>: Bias parameter.</li>
<li><code>num_hidden::int, required</code>: Number of hidden nodes of the output.</li>
<li><code>no_bias::boolean, optional, default=False</code>: Whether to disable bias parameter.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L779' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Group-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Group-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Group</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Group(nodes :: SymbolicNode...)
</code></pre>

<p>Create a <code>SymbolicNode</code> by grouping nodes together.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L242-L246' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.IdentityAttachKLSparseReg-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.IdentityAttachKLSparseReg-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.IdentityAttachKLSparseReg</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>IdentityAttachKLSparseReg(data, sparseness_target, penalty, momentum)
</code></pre>

<p>Apply a sparse regularization to the output a sigmoid activation function.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data.</li>
<li><code>sparseness_target::float, optional, default=0.1</code>: The sparseness target</li>
<li><code>penalty::float, optional, default=0.001</code>: The tradeoff parameter for the sparseness penalty</li>
<li><code>momentum::float, optional, default=0.9</code>: The momentum for running average</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L774' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.InstanceNorm-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.InstanceNorm-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.InstanceNorm</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>InstanceNorm(data, gamma, beta, eps)
</code></pre>

<p>An operator taking in a n-dimensional input tensor (n &gt; 2), and normalizing the input by subtracting the mean and variance calculated over the spatial dimensions. This is an implemention of the operator described in "Instance Normalization: The Missing Ingredient for Fast Stylization", D. Ulyanov, A. Vedaldi, V. Lempitsky, 2016 (arXiv:1607.08022v2). This layer is similar to batch normalization, with two differences: first, the normalization is carried out per example ('instance'), not over a batch. Second, the same normalization is applied both at test and train time. This operation is also known as 'contrast normalization'.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: A n-dimensional tensor (n &gt; 2) of the form [batch, channel, spatial_dim1, spatial_dim2, ...].</li>
<li><code>gamma::SymbolicNode</code>: A vector of length 'channel', which multiplies the normalized input.</li>
<li><code>beta::SymbolicNode</code>: A vector of length 'channel', which is added to the product of the normalized input and the weight.</li>
<li><code>eps::float, optional, default=0.001</code>: Epsilon to prevent division by 0.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L774' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.L2Normalization-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.L2Normalization-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.L2Normalization</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>L2Normalization(data, eps, mode)
</code></pre>

<p>Set the l2 norm of each instance to a constant.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to the L2NormalizationOp.</li>
<li><code>eps::float, optional, default=1e-10</code>: Epsilon to prevent div 0</li>
<li><code>mode::{'channel', 'instance', 'spatial'},optional, default='instance'</code>: Normalization Mode. If set to instance, this operator will compute a norm for each instance in the batch; this is the default mode. If set to channel, this operator will compute a cross channel norm at each position of each instance. If set to spatial, this operator will compute a norm for each channel.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L772' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.LRN-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.LRN-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.LRN</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>LRN(data, alpha, beta, knorm, nsize)
</code></pre>

<p>Apply convolution to input then add a bias.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to the ConvolutionOp.</li>
<li><code>alpha::float, optional, default=0.0001</code>: value of the alpha variance scaling parameter in the normalization formula</li>
<li><code>beta::float, optional, default=0.75</code>: value of the beta power parameter in the normalization formula</li>
<li><code>knorm::float, optional, default=2</code>: value of the k parameter in normalization formula</li>
<li><code>nsize::int (non-negative), required</code>: normalization window width in elements.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L776' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.LeakyReLU-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.LeakyReLU-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.LeakyReLU</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>LeakyReLU(data, act_type, slope, lower_bound, upper_bound)
</code></pre>

<p>Apply activation function to input.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to activation function.</li>
<li><code>act_type::{'elu', 'leaky', 'prelu', 'rrelu'},optional, default='leaky'</code>: Activation function to be applied.</li>
<li><code>slope::float, optional, default=0.25</code>: Init slope for the activation. (For leaky and elu only)</li>
<li><code>lower_bound::float, optional, default=0.125</code>: Lower bound of random slope. (For rrelu only)</li>
<li><code>upper_bound::float, optional, default=0.334</code>: Upper bound of random slope. (For rrelu only)</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L776' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.LinearRegressionOutput-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.LinearRegressionOutput-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.LinearRegressionOutput</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>LinearRegressionOutput(data, label, grad_scale)
</code></pre>

<p>Use linear regression for final output, this is used on final output of a net.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to function.</li>
<li><code>label::SymbolicNode</code>: Input label to function.</li>
<li><code>grad_scale::float, optional, default=1</code>: Scale the gradient by a float factor</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L772' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.LogisticRegressionOutput-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.LogisticRegressionOutput-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.LogisticRegressionOutput</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>LogisticRegressionOutput(data, label, grad_scale)
</code></pre>

<p>Use Logistic regression for final output, this is used on final output of a net. Logistic regression is suitable for binary classification or probability prediction tasks.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to function.</li>
<li><code>label::SymbolicNode</code>: Input label to function.</li>
<li><code>grad_scale::float, optional, default=1</code>: Scale the gradient by a float factor</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L773' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.MAERegressionOutput-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.MAERegressionOutput-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.MAERegressionOutput</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>MAERegressionOutput(data, label, grad_scale)
</code></pre>

<p>Use mean absolute error regression for final output, this is used on final output of a net.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to function.</li>
<li><code>label::SymbolicNode</code>: Input label to function.</li>
<li><code>grad_scale::float, optional, default=1</code>: Scale the gradient by a float factor</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L772' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.MakeLoss-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.MakeLoss-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.MakeLoss</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>MakeLoss(data, grad_scale, valid_thresh, normalization)
</code></pre>

<p>Get output from a symbol and pass 1 gradient back. This is used as a terminal loss if unary and binary operator are used to composite a loss with no declaration of backward dependency</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data.</li>
<li><code>grad_scale::float, optional, default=1</code>: gradient scale as a supplement to unary and binary operators</li>
<li><code>valid_thresh::float, optional, default=0</code>: regard element valid when x &gt; valid_thresh, this is used only in valid normalization mode.</li>
<li><code>normalization::{'batch', 'null', 'valid'},optional, default='null'</code>: If set to null, op will not normalize on output gradient.If set to batch, op will normalize gradient by divide batch size.If set to valid, op will normalize gradient by divide # sample marked as valid</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L774' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Pad-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Pad-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Pad</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Pad(data, mode, pad_width, constant_value)
</code></pre>

<p>Pads an n-dimensional input tensor. Allows for precise control of the padding type and how much padding to apply on both sides of a given dimension.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: An n-dimensional input tensor.</li>
<li><code>mode::{'constant', 'edge'}, required</code>: Padding type to use. "constant" pads all values with a constant value, the value of which can be specified with the constant_value option. "edge" uses the boundary values of the array as padding.</li>
<li><code>pad_width::Shape(tuple), required</code>: A tuple of padding widths of length 2*r, where r is the rank of the input tensor, specifying number of values padded to the edges of each axis. (before_1, after_1, ... , before_N, after_N) unique pad widths for each axis. Equivalent to pad_width in numpy.pad, but flattened.</li>
<li><code>constant_value::double, optional, default=0</code>: This option is only used when mode is "constant". This value will be used as the padding value. Defaults to 0 if not specified.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L774' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Pooling-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Pooling-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Pooling</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Pooling(data, global_pool, kernel, pool_type, pooling_convention, stride, pad)
</code></pre>

<p>Perform spatial pooling on inputs.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to the pooling operator.</li>
<li><code>global_pool::boolean, optional, default=False</code>: Ignore kernel size, do global pooling based on current input feature map. This is useful for input with different shape</li>
<li><code>kernel::Shape(tuple), required</code>: pooling kernel size: (y, x) or (d, y, x)</li>
<li><code>pool_type::{'avg', 'max', 'sum'}, required</code>: Pooling type to be applied.</li>
<li><code>pooling_convention::{'full', 'valid'},optional, default='valid'</code>: Pooling convention to be applied.kValid is default setting of Mxnet and rounds down the output pooling size.kFull is compatible with Caffe and rounds up the output pooling size.</li>
<li><code>stride::Shape(tuple), optional, default=(1,1)</code>: stride: for pooling (y, x) or (d, y, x)</li>
<li><code>pad::Shape(tuple), optional, default=(0,0)</code>: pad for pooling: (y, x) or (d, y, x)</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L780' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.RNN-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.RNN-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.RNN</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>RNN(data, parameters, state, state_cell, state_size, num_layers, bidirectional, mode, p, state_outputs)
</code></pre>

<p>Apply a recurrent layer to input.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to RNN</li>
<li><code>parameters::SymbolicNode</code>: Vector of all RNN trainable parameters concatenated</li>
<li><code>state::SymbolicNode</code>: initial hidden state of the RNN</li>
<li><code>state_cell::SymbolicNode</code>: initial cell state for LSTM networks (only for LSTM)</li>
<li><code>state_size::int (non-negative), required</code>: size of the state for each layer</li>
<li><code>num_layers::int (non-negative), required</code>: number of stacked layers</li>
<li><code>bidirectional::boolean, optional, default=False</code>: whether to use bidirectional recurrent layers</li>
<li><code>mode::{'gru', 'lstm', 'rnn_relu', 'rnn_tanh'}, required</code>: the type of RNN to compute</li>
<li><code>p::float, optional, default=0</code>: Dropout probability, fraction of the input that gets dropped out at training time</li>
<li><code>state_outputs::boolean, optional, default=False</code>: Whether to have the states as symbol outputs.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L786' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.ROIPooling-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.ROIPooling-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.ROIPooling</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>ROIPooling(data, rois, pooled_size, spatial_scale)
</code></pre>

<p>Performs region-of-interest pooling on inputs. Resize bounding box coordinates by spatial_scale and crop input feature maps accordingly. The cropped feature maps are pooled by max pooling to a fixed size output indicated by pooled_size. batch_size will change to the number of region bounding boxes after ROIPooling</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to the pooling operator, a 4D Feature maps</li>
<li><code>rois::SymbolicNode</code>: Bounding box coordinates, a 2D array of [[batch_index, x1, y1, x2, y2]]. (x1, y1) and (x2, y2) are top left and down right corners of designated region of interest. batch_index indicates the index of corresponding image in the input data</li>
<li><code>pooled_size::Shape(tuple), required</code>: fix pooled size: (h, w)</li>
<li><code>spatial_scale::float, required</code>: Ratio of input feature map height (or w) to raw image height (or w). Equals the reciprocal of total stride in convolutional layers</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L774' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Reshape-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Reshape-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Reshape</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Reshape(data, target_shape, keep_highest, shape, reverse)
</code></pre>

<p>Reshape input according to a target shape spec. The target shape is a tuple and can be a simple list of dimensions such as (12,3) or it can incorporate special codes that correspond to contextual operations that refer to the input dimensions. The special codes are all expressed as integers less than 1. These codes effectively refer to a machine that pops input dims off the beginning of the input dims list and pushes resulting output dims onto the end of the output dims list, which starts empty. The codes are:   0  Copy     Pop one input dim and push it onto the output dims  -1  Infer    Push a dim that is inferred later from all other output dims  -2  CopyAll  Pop all remaining input dims and push them onto output dims  -3  Merge2   Pop two input dims, multiply them, and push result  -4  Split2   Pop one input dim, and read two next target shape specs,               push them both onto output dims (either can be -1 and will               be inferred from the other  The exact mathematical behavior of these codes is given in the description of the 'shape' parameter. All non-codes (positive integers) just pop a dim off the input dims (if any), throw it away, and then push the specified integer onto the output dims. Examples: Type     Input      Target            Output Copy     (2,3,4)    (4,0,2)           (4,3,2) Copy     (2,3,4)    (2,0,0)           (2,3,4) Infer    (2,3,4)    (6,1,-1)          (6,1,4) Infer    (2,3,4)    (3,-1,8)          (3,1,8) CopyAll  (9,8,7)    (-2)              (9,8,7) CopyAll  (9,8,7)    (9,-2)            (9,8,7) CopyAll  (9,8,7)    (-2,1,1)          (9,8,7,1,1) Merge2   (3,4)      (-3)              (12) Merge2   (3,4,5)    (-3,0)            (12,5) Merge2   (3,4,5)    (0,-3)            (3,20) Merge2   (3,4,5,6)  (-3,0,0)          (12,5,6) Merge2   (3,4,5,6)  (-3,-2)           (12,5,6) Split2   (12)       (-4,6,2)          (6,2) Split2   (12)       (-4,2,6)          (2,6) Split2   (12)       (-4,-1,6)         (2,6) Split2   (12,9)     (-4,2,6,0)        (2,6,9) Split2   (12,9,9,9) (-4,2,6,-2)       (2,6,9,9,9) Split2   (12,12)    (-4,2,-1,-4,-1,2) (2,6,6,2)</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to reshape.</li>
<li><code>target_shape::Shape(tuple), optional, default=(0,0)</code>: (Deprecated! Use shape instead.) Target new shape. One and only one dim can be 0, in which case it will be inferred from the rest of dims</li>
<li><code>keep_highest::boolean, optional, default=False</code>: (Deprecated! Use shape instead.) Whether keep the highest dim unchanged.If set to true, then the first dim in target_shape is ignored,and always fixed as input</li>
<li><code>shape::, optional, default=()</code>: Target shape, a tuple, t=(t_1,t_2,..,t_m).</li>
</ul>
<p>Let the input dims be s=(s_1,s_2,..,s_n). The output dims u=(u_1,u_2,..,u_p) are computed from s and t. The target shape tuple elements t_i are read in order, and used to  generate successive output dims u_p: t_i:       meaning:      behavior: +ve        explicit      u_p = t_i 0          copy          u_p = s_i -1         infer         u_p = (Prod s_i) / (Prod u_j | j != p) -2         copy all      u_p = s_i, u_p+1 = s_i+1, ... -3         merge two     u_p = s_i * s_i+1 -4,a,b     split two     u_p = a, u_p+1 = b | a * b = s_i The split directive (-4) in the target shape tuple is followed by two dimensions, one of which can be -1, which means it will be inferred from the other one and the original dimension. The can only be one globally inferred dimension (-1), aside from any -1 occuring in a split directive.</p>
<ul>
<li><code>reverse::boolean, optional, default=False</code>: Whether to match the shapes from the backward. If reverse is true, 0 values in the <code>shape</code> argument will be searched from the backward. E.g the original shape is (10, 5, 4) and the shape argument is (-1, 0). If reverse is true, the new shape should be (50, 4). Otherwise it will be (40, 5).</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L819' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.SVMOutput-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.SVMOutput-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.SVMOutput</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>SVMOutput(data, label, margin, regularization_coefficient, use_linear)
</code></pre>

<p>Support Vector Machine based transformation on input, backprop L2-SVM</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to svm.</li>
<li><code>label::SymbolicNode</code>: Label data.</li>
<li><code>margin::float, optional, default=1</code>: Scale the DType(param_.margin) for activation size</li>
<li><code>regularization_coefficient::float, optional, default=1</code>: Scale the coefficient responsible for balacing coefficient size and error tradeoff</li>
<li><code>use_linear::boolean, optional, default=False</code>: If set true, uses L1-SVM objective function. Default uses L2-SVM objective</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L776' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.SequenceLast-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.SequenceLast-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.SequenceLast</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>SequenceLast(data, sequence_length, use_sequence_length)
</code></pre>

<p>Takes the last element of a sequence. Takes an n-dimensional tensor of the form [max sequence length, batchsize, other dims] and returns a (n-1)-dimensional tensor of the form [batchsize, other dims]. This operator takes an optional input tensor sequence_length of positive ints of dimension [batchsize] when the sequence_length option is set to true. This allows the operator to handle variable-length sequences. If sequence_length is false, then each example in the batch is assumed to have the max sequence length.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: n-dimensional input tensor of the form [max sequence length, batchsize, other dims]</li>
<li><code>sequence_length::SymbolicNode</code>: vector of sequence lengths of size batchsize</li>
<li><code>use_sequence_length::boolean, optional, default=False</code>: If set to true, this layer takes in extra input sequence_length to specify variable length sequence</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L772' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.SequenceMask-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.SequenceMask-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.SequenceMask</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>SequenceMask(data, sequence_length, use_sequence_length, value)
</code></pre>

<p>Sets all elements outside the sequence to a constant value. Takes an n-dimensional tensor of the form [max sequence length, batchsize, other dims] and returns a tensor of the same shape. This operator takes an optional input tensor sequence_length of positive ints of dimension [batchsize] when the sequence_length option is set to true. This allows the operator to handle variable-length sequences. If sequence_length is false, then each example in the batch is assumed to have the max sequence length, and this operator becomes the identity operator.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: n-dimensional input tensor of the form [max sequence length, batchsize, other dims]</li>
<li><code>sequence_length::SymbolicNode</code>: vector of sequence lengths of size batchsize</li>
<li><code>use_sequence_length::boolean, optional, default=False</code>: If set to true, this layer takes in extra input sequence_length to specify variable length sequence</li>
<li><code>value::float, optional, default=0</code>: The value to be used as a mask.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L774' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.SequenceReverse-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.SequenceReverse-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.SequenceReverse</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>SequenceReverse(data, sequence_length, use_sequence_length)
</code></pre>

<p>Reverses the elements of each sequence. Takes an n-dimensional tensor of the form [max sequence length, batchsize, other dims] and returns a tensor of the same shape. This operator takes an optional input tensor sequence_length of positive ints of dimension [batchsize] when the sequence_length option is set to true. This allows the operator to handle variable-length sequences. If sequence_length is false, then each example in the batch is assumed to have the max sequence length.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: n-dimensional input tensor of the form [max sequence length, batchsize, other dims]</li>
<li><code>sequence_length::SymbolicNode</code>: vector of sequence lengths of size batchsize</li>
<li><code>use_sequence_length::boolean, optional, default=False</code>: If set to true, this layer takes in extra input sequence_length to specify variable length sequence</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L772' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.SliceChannel-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.SliceChannel-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.SliceChannel</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>SliceChannel(num_outputs, axis, squeeze_axis)
</code></pre>

<p>Slice input equally along specified axis</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>num_outputs::int, required</code>: Number of outputs to be sliced.</li>
<li><code>axis::int, optional, default='1'</code>: Dimension along which to slice.</li>
<li><code>squeeze_axis::boolean, optional, default=False</code>: If true AND the sliced dimension becomes 1, squeeze that dimension.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode[]</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L772' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Softmax-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.Softmax-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.Softmax</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Softmax(data, grad_scale, ignore_label, multi_output, use_ignore, preserve_shape, normalization, out_grad)
</code></pre>

<p>DEPRECATED: Perform a softmax transformation on input. Please use SoftmaxOutput</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to softmax.</li>
<li><code>grad_scale::float, optional, default=1</code>: Scale the gradient by a float factor</li>
<li><code>ignore_label::float, optional, default=-1</code>: the label value will be ignored during backward (only works if use_ignore is set to be true).</li>
<li><code>multi_output::boolean, optional, default=False</code>: If set to true, for a (n,k,x_1,..,x_n) dimensional input tensor, softmax will generate n<em>x_1</em>...*x_n output, each has k classes</li>
<li><code>use_ignore::boolean, optional, default=False</code>: If set to true, the ignore_label value will not contribute to the backward gradient</li>
<li><code>preserve_shape::boolean, optional, default=False</code>: If true, for a (n_1, n_2, ..., n_d, k) dimensional input tensor, softmax will generate (n1, n2, ..., n_d, k) output, normalizing the k classes as the last dimension.</li>
<li><code>normalization::{'batch', 'null', 'valid'},optional, default='null'</code>: If set to null, op will do nothing on output gradient.If set to batch, op will normalize gradient by divide batch sizeIf set to valid, op will normalize gradient by divide sample not ignored</li>
<li><code>out_grad::boolean, optional, default=False</code>: Apply weighting from output gradient</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L782' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.SoftmaxActivation-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.SoftmaxActivation-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.SoftmaxActivation</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>SoftmaxActivation(data, mode)
</code></pre>

<p>Apply softmax activation to input. This is intended for internal layers. For output (loss layer) please use SoftmaxOutput. If mode=instance, this operator will compute a softmax for each instance in the batch; this is the default mode. If mode=channel, this operator will compute a num_channel-class softmax at each position of each instance; this can be used for fully convolutional network, image segmentation, etc.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to activation function.</li>
<li><code>mode::{'channel', 'instance'},optional, default='instance'</code>: Softmax Mode. If set to instance, this operator will compute a softmax for each instance in the batch; this is the default mode. If set to channel, this operator will compute a num_channel-class softmax at each position of each instance; this can be used for fully convolutional network, image segmentation, etc.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.SoftmaxOutput-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.SoftmaxOutput-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.SoftmaxOutput</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>SoftmaxOutput(data, label, grad_scale, ignore_label, multi_output, use_ignore, preserve_shape, normalization, out_grad)
</code></pre>

<p>Perform a softmax transformation on input, backprop with logloss.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to softmax.</li>
<li><code>label::SymbolicNode</code>: Label data, can also be probability value with same shape as data</li>
<li><code>grad_scale::float, optional, default=1</code>: Scale the gradient by a float factor</li>
<li><code>ignore_label::float, optional, default=-1</code>: the label value will be ignored during backward (only works if use_ignore is set to be true).</li>
<li><code>multi_output::boolean, optional, default=False</code>: If set to true, for a (n,k,x_1,..,x_n) dimensional input tensor, softmax will generate n<em>x_1</em>...*x_n output, each has k classes</li>
<li><code>use_ignore::boolean, optional, default=False</code>: If set to true, the ignore_label value will not contribute to the backward gradient</li>
<li><code>preserve_shape::boolean, optional, default=False</code>: If true, for a (n_1, n_2, ..., n_d, k) dimensional input tensor, softmax will generate (n1, n2, ..., n_d, k) output, normalizing the k classes as the last dimension.</li>
<li><code>normalization::{'batch', 'null', 'valid'},optional, default='null'</code>: If set to null, op will do nothing on output gradient.If set to batch, op will normalize gradient by divide batch sizeIf set to valid, op will normalize gradient by divide sample not ignored</li>
<li><code>out_grad::boolean, optional, default=False</code>: Apply weighting from output gradient</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L784' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.SpatialTransformer-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.SpatialTransformer-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.SpatialTransformer</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>SpatialTransformer(data, loc, target_shape, transform_type, sampler_type)
</code></pre>

<p>Apply spatial transformer to input feature map.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to the SpatialTransformerOp.</li>
<li><code>loc::SymbolicNode</code>: localisation net, the output dim should be 6 when transform_type is affine, and the name of loc symbol should better starts with 'stn_loc', so that initialization it with iddentify tranform, or you shold initialize the weight and bias by yourself.</li>
<li><code>target_shape::Shape(tuple), optional, default=(0,0)</code>: output shape(h, w) of spatial transformer: (y, x)</li>
<li><code>transform_type::{'affine'}, required</code>: transformation type</li>
<li><code>sampler_type::{'bilinear'}, required</code>: sampling type</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L776' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.SwapAxis-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.SwapAxis-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.SwapAxis</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>SwapAxis(data, dim1, dim2)
</code></pre>

<p>Apply swapaxis to input.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode</code>: Input data to the SwapAxisOp.</li>
<li><code>dim1::int (non-negative), optional, default=0</code>: the first axis to be swapped.</li>
<li><code>dim2::int (non-negative), optional, default=0</code>: the second axis to be swapped.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L772' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.UpSampling-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.UpSampling-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.UpSampling</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>UpSampling(data, scale, num_filter, sample_type, multi_input_mode, num_args, workspace)
</code></pre>

<p>Perform nearest neighboor/bilinear up sampling to inputs</p>
<p>This function support variable length positional <code>SymbolicNode</code> inputs.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>data::SymbolicNode[]</code>: Array of tensors to upsample</li>
<li><code>scale::int (non-negative), required</code>: Up sampling scale</li>
<li><code>num_filter::int (non-negative), optional, default=0</code>: Input filter. Only used by bilinear sample_type.</li>
<li><code>sample_type::{'bilinear', 'nearest'}, required</code>: upsampling method</li>
<li><code>multi_input_mode::{'concat', 'sum'},optional, default='concat'</code>: How to handle multiple input. concat means concatenate upsampled images along the channel dimension. sum means add all images together, only available for nearest neighbor upsampling.</li>
<li><code>num_args::int, required</code>: Number of inputs to be upsampled. For nearest neighbor upsampling, this can be 1-N; the size of output will be(scale<em>h_0,scale</em>w_0) and all other inputs will be upsampled to thesame size. For bilinear upsampling this must be 2; 1 input and 1 weight.</li>
<li><code>workspace::long (non-negative), optional, default=512</code>: Tmp workspace for deconvolution (MB)</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L782' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.Variable-Tuple{Union{AbstractString,Symbol}}' href='#MXNet.mx.Variable-Tuple{Union{AbstractString,Symbol}}'>#</a>
<strong><code>MXNet.mx.Variable</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>Variable(name :: Union{Symbol, AbstractString})
</code></pre>

<p>Create a symbolic variable with the given name. This is typically used as a placeholder. For example, the data node, acting as the starting point of a network architecture.</p>
<p><strong>Arguments</strong></p>
<ul>
<li>Dict{Symbol, AbstractString} attrs: The attributes associated with this <code>Variable</code>.</li>
</ul>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L222-L230' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._CrossDeviceCopy-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._CrossDeviceCopy-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._CrossDeviceCopy</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_CrossDeviceCopy()
</code></pre>

<p>Special op to copy data cross device</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L767' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._Div-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._Div-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._Div</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_Div(lhs, rhs)
</code></pre>

<p>Multiply lhs by rhs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._DivScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._DivScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._DivScalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_DivScalar(src)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._Maximum-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._Maximum-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._Maximum</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_Maximum(lhs, rhs)
</code></pre>

<p>Elementwise max of lhs by rhs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._MaximumScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._MaximumScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._MaximumScalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_MaximumScalar(src)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._Minimum-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._Minimum-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._Minimum</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_Minimum(lhs, rhs)
</code></pre>

<p>Elementwise min of lhs by rhs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._MinimumScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._MinimumScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._MinimumScalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_MinimumScalar(src)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._Minus-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._Minus-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._Minus</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_Minus(lhs, rhs)
</code></pre>

<p>Minus lhs and rhs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._MinusScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._MinusScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._MinusScalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_MinusScalar(src)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._Mul-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._Mul-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._Mul</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_Mul(lhs, rhs)
</code></pre>

<p>Multiply lhs and rhs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._MulScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._MulScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._MulScalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_MulScalar(src)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._NDArray-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._NDArray-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._NDArray</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_NDArray(info)
</code></pre>

<p>Stub for implementing an operator implemented in native frontend language with ndarray.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>info::, required</code>:</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._Native-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._Native-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._Native</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_Native(info, need_top_grad)
</code></pre>

<p>Stub for implementing an operator implemented in native frontend language.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>info::, required</code>:</li>
<li><code>need_top_grad::boolean, optional, default=True</code>: Whether this layer needs out grad for backward. Should be false for loss layers.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._Plus-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._Plus-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._Plus</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_Plus(lhs, rhs)
</code></pre>

<p>Add lhs and rhs</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._PlusScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._PlusScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._PlusScalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_PlusScalar(src)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._Power-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._Power-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._Power</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_Power(lhs, rhs)
</code></pre>

<p>Elementwise power(lhs, rhs)</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._PowerScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._PowerScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._PowerScalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_PowerScalar(src)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._RDivScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._RDivScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._RDivScalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_RDivScalar(src)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._RMinusScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._RMinusScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._RMinusScalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_RMinusScalar(src)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx._RPowerScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx._RPowerScalar-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx._RPowerScalar</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>_RPowerScalar(src)
</code></pre>

<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.batch_dot-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.batch_dot-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.batch_dot</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>batch_dot(lhs, rhs)
</code></pre>

<p>Calculate batched dot product of two matrices. (batch, M, K) batch_dot (batch, K, N) &gt; (batch, M, N)</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_axis-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.broadcast_axis-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.broadcast_axis</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_axis(src, axis, size)
</code></pre>

<p>Broadcast data in the given axis to the given size. The original size of the broadcasting axis must be 1.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>axis::Shape(tuple), optional, default=()</code>: The axes to perform the broadcasting.</li>
<li><code>size::Shape(tuple), optional, default=()</code>: Target sizes of the broadcasting axes.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L772' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_div-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.broadcast_div-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.broadcast_div</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_div(lhs, rhs)
</code></pre>

<p>lhs divide rhs with broadcast</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_minus-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.broadcast_minus-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.broadcast_minus</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_minus(lhs, rhs)
</code></pre>

<p>lhs minus rhs with broadcast</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_mul-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.broadcast_mul-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.broadcast_mul</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_mul(lhs, rhs)
</code></pre>

<p>lhs multiple rhs with broadcast</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_plus-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.broadcast_plus-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.broadcast_plus</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_plus(lhs, rhs)
</code></pre>

<p>lhs add rhs with broadcast</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_power-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.broadcast_power-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.broadcast_power</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_power(lhs, rhs)
</code></pre>

<p>lhs power rhs with broadcast</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.broadcast_to-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.broadcast_to-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.broadcast_to</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>broadcast_to(src, shape)
</code></pre>

<p>Broadcast data to the target shape. The original size of the broadcasting axis must be 1.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>shape::Shape(tuple), optional, default=()</code>: The shape of the desired array. We can set the dim to zero if it's same as the original. E.g <code>A = broadcast_to(B, shape=(10, 0, 0))</code> has the same meaning as <code>A = broadcast_axis(B, axis=0, size=10)</code>.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.element_mask-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.element_mask-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.element_mask</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>element_mask(lhs, rhs)
</code></pre>

<p>rhs elmentwise mask lhs with broadcast</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.expand_dims-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.expand_dims-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.expand_dims</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>expand_dims(src, axis)
</code></pre>

<p>Expand the shape of array by inserting a new axis.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>axis::int (non-negative), required</code>: Position (amongst axes) where new axis is to be inserted.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.from_json-Tuple{AbstractString,Type{MXNet.mx.SymbolicNode}}' href='#MXNet.mx.from_json-Tuple{AbstractString,Type{MXNet.mx.SymbolicNode}}'>#</a>
<strong><code>MXNet.mx.from_json</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>from_json(repr :: AbstractString, ::Type{SymbolicNode})
</code></pre>

<p>Load a <code>SymbolicNode</code> from a JSON string representation.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L556-L560' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.get_attr-Tuple{MXNet.mx.SymbolicNode,Symbol}' href='#MXNet.mx.get_attr-Tuple{MXNet.mx.SymbolicNode,Symbol}'>#</a>
<strong><code>MXNet.mx.get_attr</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>get_attr(self :: SymbolicNode, key :: Symbol)
</code></pre>

<p>Get attribute attached to this <code>SymbolicNode</code> belonging to key.</p>
<p>Returns the value belonging to key as a <code>Nullable</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L118-L124' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.get_internals-Tuple{MXNet.mx.SymbolicNode}' href='#MXNet.mx.get_internals-Tuple{MXNet.mx.SymbolicNode}'>#</a>
<strong><code>MXNet.mx.get_internals</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>get_internals(self :: SymbolicNode)
</code></pre>

<p>Get a new grouped <code>SymbolicNode</code> whose output contains all the internal outputs of this <code>SymbolicNode</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L106-L111' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.grad-Tuple{MXNet.mx.SymbolicNode,Array{Symbol,1}}' href='#MXNet.mx.grad-Tuple{MXNet.mx.SymbolicNode,Array{Symbol,1}}'>#</a>
<strong><code>MXNet.mx.grad</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>grad(self :: SymbolicNode, wrt :: Vector{SymbolicNode})
</code></pre>

<p>Get the autodiff gradient of the current <code>SymbolicNode</code>. This function can only be used if the current symbol is a loss function.</p>
<p><strong>Arguments:</strong></p>
<ul>
<li><code>self::SymbolicNode</code>: current node.</li>
<li><code>wrt::Vector{Symbol}</code>: the names of the arguments to the gradient.</li>
</ul>
<p>Returns a gradient symbol of the corresponding gradient.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L202-L213' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.infer_shape-Tuple{MXNet.mx.SymbolicNode}' href='#MXNet.mx.infer_shape-Tuple{MXNet.mx.SymbolicNode}'>#</a>
<strong><code>MXNet.mx.infer_shape</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>infer_shape(self :: SymbolicNode, args...)
infer_shape(self :: SymbolicNode; kwargs...)
</code></pre>

<p>Do shape inference according to the input shapes. The input shapes could be provided as a list of shapes, which should specify the shapes of inputs in the same order as the arguments returned by <a href="./#MXNet.mx.list_arguments-Tuple{MXNet.mx.SymbolicNode}"><code>list_arguments</code></a>. Alternatively, the shape information could be specified via keyword arguments.</p>
<p>Returns a 3-tuple containing shapes of all the arguments, shapes of all the outputs and shapes of all the auxiliary variables. If shape inference failed due to incomplete or incompatible inputs, the return value will be <code>(nothing, nothing, nothing)</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L298-L310' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.infer_type-Tuple{MXNet.mx.SymbolicNode}' href='#MXNet.mx.infer_type-Tuple{MXNet.mx.SymbolicNode}'>#</a>
<strong><code>MXNet.mx.infer_type</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>infer_type(self :: SymbolicNode; kwargs...)
infer_type(self :: SymbolicNode, args...)
</code></pre>

<p>Do type inference according to the input types. The input types could be provided as a list of types, which should specify the types of inputs in the same order as the arguments returned by <a href="./#MXNet.mx.list_arguments-Tuple{MXNet.mx.SymbolicNode}"><code>list_arguments</code></a>. Alternatively, the type information could be specified via keyword arguments.</p>
<p>Returns a 3-tuple containing types of all the arguments, types of all the outputs and types of all the auxiliary variables. If type inference failed due to incomplete or incompatible inputs, the return value will be <code>(nothing, nothing, nothing)</code>.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L366-L378' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.list_all_attr-Tuple{MXNet.mx.SymbolicNode}' href='#MXNet.mx.list_all_attr-Tuple{MXNet.mx.SymbolicNode}'>#</a>
<strong><code>MXNet.mx.list_all_attr</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>list_all_attr(self :: SymbolicNode)
</code></pre>

<p>Get all attributes from the symbol graph.</p>
<p>Returns a dictionary of attributes.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L161-L167' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.list_arguments-Tuple{MXNet.mx.SymbolicNode}' href='#MXNet.mx.list_arguments-Tuple{MXNet.mx.SymbolicNode}'>#</a>
<strong><code>MXNet.mx.list_arguments</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>list_arguments(self :: SymbolicNode)
</code></pre>

<p>List all the arguments of this node. The argument for a node contains both the inputs and parameters. For example, a <code>FullyConnected</code> node will have both data and weights in its arguments. A composed node (e.g. a MLP) will list all the arguments for intermediate nodes.</p>
<p>Returns a list of symbols indicating the names of the arguments.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L63-L72' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.list_attr-Tuple{MXNet.mx.SymbolicNode}' href='#MXNet.mx.list_attr-Tuple{MXNet.mx.SymbolicNode}'>#</a>
<strong><code>MXNet.mx.list_attr</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>list_attr(self :: SymbolicNode)
</code></pre>

<p>Get all attributes from a symbol.</p>
<p>Returns a dictionary of attributes.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L138-L144' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.list_auxiliary_states-Tuple{MXNet.mx.SymbolicNode}' href='#MXNet.mx.list_auxiliary_states-Tuple{MXNet.mx.SymbolicNode}'>#</a>
<strong><code>MXNet.mx.list_auxiliary_states</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>list_auxiliary_states(self :: SymbolicNode)
</code></pre>

<p>List all auxiliary states in the symbool.</p>
<p>Auxiliary states are special states of symbols that do not corresponds to an argument, and do not have gradient. But still be useful for the specific operations. A common example of auxiliary state is the moving_mean and moving_variance in BatchNorm. Most operators do not have Auxiliary states.</p>
<p>Returns a list of symbols indicating the names of the auxiliary states.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L89-L101' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.list_outputs-Tuple{MXNet.mx.SymbolicNode}' href='#MXNet.mx.list_outputs-Tuple{MXNet.mx.SymbolicNode}'>#</a>
<strong><code>MXNet.mx.list_outputs</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>list_outputs(self :: SymbolicNode)
</code></pre>

<p>List all the outputs of this node.</p>
<p>Returns a list of symbols indicating the names of the outputs.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L77-L83' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.load-Tuple{AbstractString,Type{MXNet.mx.SymbolicNode}}' href='#MXNet.mx.load-Tuple{AbstractString,Type{MXNet.mx.SymbolicNode}}'>#</a>
<strong><code>MXNet.mx.load</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>load(filename :: AbstractString, ::Type{SymbolicNode})
</code></pre>

<p>Load a <code>SymbolicNode</code> from a JSON file.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L567-L571' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.normal-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.normal-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.normal</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>normal(loc, scale, shape)
</code></pre>

<p>Sample a normal distribution</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>loc::float, optional, default=0</code>: Mean of the distribution.</li>
<li><code>scale::float, optional, default=1</code>: Standard deviation of the distribution.</li>
<li><code>shape::Shape(tuple), required</code>: The shape of the output</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L772' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.rsqrt-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.rsqrt-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.rsqrt</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>rsqrt(src)
</code></pre>

<p>Take rsqrt of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.save-Tuple{AbstractString,MXNet.mx.SymbolicNode}' href='#MXNet.mx.save-Tuple{AbstractString,MXNet.mx.SymbolicNode}'>#</a>
<strong><code>MXNet.mx.save</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>save(filename :: AbstractString, node :: SymbolicNode)
</code></pre>

<p>Save a <code>SymbolicNode</code> to a JSON file.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L578-L582' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.set_attr-Tuple{MXNet.mx.SymbolicNode,Symbol,AbstractString}' href='#MXNet.mx.set_attr-Tuple{MXNet.mx.SymbolicNode,Symbol,AbstractString}'>#</a>
<strong><code>MXNet.mx.set_attr</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>set_attr(self:: SymbolicNode, key :: Symbol, value :: AbstractString)
</code></pre>

<p>Set the attribute key to value for this <code>SymbolicNode</code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is encouraged not to call this function directly, unless you know exactly what you are doing. The recommended way of setting attributes is when creating the <code>SymbolicNode</code>. Changing the attributes of a <code>SymbolicNode</code> that is already been used somewhere else might cause unexpected behavior and inconsistency.</p>
</div>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L184-L194' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.slice_axis-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.slice_axis-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.slice_axis</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>slice_axis(src, axis, begin, end)
</code></pre>

<p>Slice the input along certain axis and return a sliced array.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>axis::int, required</code>: The axis to be sliced</li>
<li><code>begin::int, required</code>: The beginning index to be sliced</li>
<li><code>end::int, required</code>: The end index to be sliced</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L774' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.smooth_l1-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.smooth_l1-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.smooth_l1</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>smooth_l1(src)
</code></pre>

<p>Calculate Smooth L1 Loss(lhs, scalar)</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.softmax_cross_entropy-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.softmax_cross_entropy-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.softmax_cross_entropy</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>softmax_cross_entropy(lhs, rhs)
</code></pre>

<p>Calculate cross_entropy(lhs, one_hot(rhs))</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>lhs::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>rhs::SymbolicNode</code>: Right symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L770' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.square-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.square-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.square</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>square(src)
</code></pre>

<p>Take square of the src</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L768' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.sum_axis-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.sum_axis-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.sum_axis</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>sum_axis(src, axis, keepdims)
</code></pre>

<p>(Depreciated! Use sum instead!) Take sum of the src in the given axis and returns a NDArray. Follows numpy semantics.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>src::SymbolicNode</code>: Left symbolic input to the function</li>
<li><code>axis::Shape(tuple), optional, default=()</code>: Same as Numpy. The axes to perform the reduction.If left empty, a global reduction will be performed.</li>
<li><code>keepdims::boolean, optional, default=False</code>: Same as Numpy. If keepdims is set to true, the axis which is reduced is left in the result as dimension with size one.</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L772' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.to_json-Tuple{MXNet.mx.SymbolicNode}' href='#MXNet.mx.to_json-Tuple{MXNet.mx.SymbolicNode}'>#</a>
<strong><code>MXNet.mx.to_json</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>to_json(self :: SymbolicNode)
</code></pre>

<p>Convert a <code>SymbolicNode</code> into a JSON string.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L545-L549' class='documenter-source'>source</a><br></p>
<p><a id='MXNet.mx.uniform-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}' href='#MXNet.mx.uniform-Tuple{Vararg{MXNet.mx.SymbolicNode,N}}'>#</a>
<strong><code>MXNet.mx.uniform</code></strong> &mdash; <em>Method</em>.</p>
<pre><code>uniform(low, high, shape)
</code></pre>

<p>Sample a uniform distribution</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>low::float, optional, default=0</code>: The lower bound of distribution</li>
<li><code>high::float, optional, default=1</code>: The upper bound of distribution</li>
<li><code>shape::Shape(tuple), required</code>: The shape of the output</li>
<li><code>name::Symbol</code>: The name of the <code>SymbolicNode</code>. (e.g. <code>:my_symbol</code>), optional.</li>
<li><code>attrs::Dict{Symbol, AbstractString}</code>: The attributes associated with this <code>SymbolicNode</code>.</li>
</ul>
<p>Returns ``.</p>
<p><a target='_blank' href='https://github.com/dmlc/MXNet.jl/tree/c06b21111971878d9a8f46c75f9a22bb668fd780/src/symbolic-node.jl#L758-L772' class='documenter-source'>source</a><br></p>
          <aside class="copyright" role="note">
            
            Documentation built with
            <a href="http://www.mkdocs.org" target="_blank">MkDocs</a>
            using the
            <a href="http://squidfunk.github.io/mkdocs-material/" target="_blank">
              Material
            </a>
            theme.
          </aside>
          
            <footer class="footer">
              
  <nav class="pagination" aria-label="Footer">
    <div class="previous">
      
        <a href="../ndarray/" title="NDArray API">
          <span class="direction">
            Previous
          </span>
          <div class="page">
            <div class="button button-previous" role="button" aria-label="Previous">
              <i class="icon icon-back"></i>
            </div>
            <div class="stretch">
              <div class="title">
                NDArray API
              </div>
            </div>
          </div>
        </a>
      
    </div>
    <div class="next">
      
        <a href="../nn-factory/" title="Neural Networks Factory">
          <span class="direction">
            Next
          </span>
          <div class="page">
            <div class="stretch">
              <div class="title">
                Neural Networks Factory
              </div>
            </div>
            <div class="button button-next" role="button" aria-label="Next">
              <i class="icon icon-forward"></i>
            </div>
          </div>
        </a>
      
    </div>
  </nav>

            </footer>
          
        </div>
      </article>
      <div class="results" role="status" aria-live="polite">
        <div class="scrollable">
          <div class="wrapper">
            <div class="meta"></div>
            <div class="list"></div>
          </div>
        </div>
      </div>
    </main>
    <script>
      var base_url = '../..';
      var repo_id  = 'dmlc/MXNet.jl';
    </script>
    <script src="../../assets/javascripts/application-997097ee0c.js"></script>
    
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.jl?config=TeX-AMS-MML_HTMLorMML"></script>
    
      <script src="../../assets/mathjaxhelper.js"></script>
    
    
  </body>
</html>